{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from itertools import combinations,permutations\n",
    "\n",
    "torch.manual_seed(99)\n",
    "np.random.seed(99)\n",
    "torch.cuda.empty_cache()\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as tf\n",
    "\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import torch\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "import plotly.graph_objects as go\n",
    "from scipy.sparse import coo_matrix\n",
    "from geopy.distance import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-95.35  28.85 \\n</th>\n",
       "      <th>-103.593750  34.656250\\n</th>\n",
       "      <th>-103.531250  34.656250\\n</th>\n",
       "      <th>-103.468750  34.656250\\n</th>\n",
       "      <th>-103.406250  34.656250\\n</th>\n",
       "      <th>-103.343750  34.656250\\n</th>\n",
       "      <th>-103.281250  34.656250\\n</th>\n",
       "      <th>-103.218750  34.656250\\n</th>\n",
       "      <th>-103.156250  34.656250\\n</th>\n",
       "      <th>-103.656250  34.593750\\n</th>\n",
       "      <th>...</th>\n",
       "      <th>-95.531250  29.031250\\n</th>\n",
       "      <th>-95.468750  29.031250\\n</th>\n",
       "      <th>-95.406250  29.031250\\n</th>\n",
       "      <th>-95.531250  28.968750\\n</th>\n",
       "      <th>-95.468750  28.968750\\n</th>\n",
       "      <th>-95.406250  28.968750\\n</th>\n",
       "      <th>-95.343750  28.968750\\n</th>\n",
       "      <th>-95.468750  28.906250\\n</th>\n",
       "      <th>-95.406250  28.906250\\n</th>\n",
       "      <th>-95.343750  28.906250\\n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.911094</td>\n",
       "      <td>-0.134267</td>\n",
       "      <td>-0.398994</td>\n",
       "      <td>0.256755</td>\n",
       "      <td>-0.383672</td>\n",
       "      <td>1.572451</td>\n",
       "      <td>-0.674415</td>\n",
       "      <td>-0.228816</td>\n",
       "      <td>0.037667</td>\n",
       "      <td>-0.532050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178725</td>\n",
       "      <td>-0.230239</td>\n",
       "      <td>-0.252408</td>\n",
       "      <td>-0.572311</td>\n",
       "      <td>0.088742</td>\n",
       "      <td>0.446975</td>\n",
       "      <td>-0.651768</td>\n",
       "      <td>-0.300383</td>\n",
       "      <td>0.901711</td>\n",
       "      <td>0.067492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035373</td>\n",
       "      <td>-0.726517</td>\n",
       "      <td>-0.466346</td>\n",
       "      <td>-0.129167</td>\n",
       "      <td>-0.578796</td>\n",
       "      <td>0.337814</td>\n",
       "      <td>-0.375985</td>\n",
       "      <td>-0.711423</td>\n",
       "      <td>-0.462730</td>\n",
       "      <td>-0.125976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337374</td>\n",
       "      <td>-0.346014</td>\n",
       "      <td>-0.374297</td>\n",
       "      <td>-0.734310</td>\n",
       "      <td>-0.044489</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>-0.418514</td>\n",
       "      <td>-0.612205</td>\n",
       "      <td>0.086772</td>\n",
       "      <td>-0.196638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.184683</td>\n",
       "      <td>-0.176776</td>\n",
       "      <td>-0.466799</td>\n",
       "      <td>-0.400074</td>\n",
       "      <td>-0.427399</td>\n",
       "      <td>-0.359177</td>\n",
       "      <td>-0.275025</td>\n",
       "      <td>-0.393831</td>\n",
       "      <td>-0.511412</td>\n",
       "      <td>-0.347567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329134</td>\n",
       "      <td>-0.343043</td>\n",
       "      <td>-0.378763</td>\n",
       "      <td>-0.592142</td>\n",
       "      <td>-0.343849</td>\n",
       "      <td>-0.497109</td>\n",
       "      <td>-0.257276</td>\n",
       "      <td>-0.389134</td>\n",
       "      <td>-0.491061</td>\n",
       "      <td>-0.162036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.184683</td>\n",
       "      <td>-0.387886</td>\n",
       "      <td>-0.594697</td>\n",
       "      <td>-0.516747</td>\n",
       "      <td>-0.469316</td>\n",
       "      <td>-0.495481</td>\n",
       "      <td>-0.543043</td>\n",
       "      <td>-0.590618</td>\n",
       "      <td>-0.496078</td>\n",
       "      <td>-0.469463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337176</td>\n",
       "      <td>-0.345840</td>\n",
       "      <td>-0.380737</td>\n",
       "      <td>-0.606311</td>\n",
       "      <td>-0.482309</td>\n",
       "      <td>-0.705154</td>\n",
       "      <td>-0.588362</td>\n",
       "      <td>-0.593416</td>\n",
       "      <td>-0.691268</td>\n",
       "      <td>-0.405932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019306</td>\n",
       "      <td>-0.445776</td>\n",
       "      <td>-0.633418</td>\n",
       "      <td>-0.487968</td>\n",
       "      <td>-0.469061</td>\n",
       "      <td>-0.491576</td>\n",
       "      <td>-0.560085</td>\n",
       "      <td>-0.603027</td>\n",
       "      <td>-0.560102</td>\n",
       "      <td>-0.470457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337135</td>\n",
       "      <td>-0.345820</td>\n",
       "      <td>-0.381714</td>\n",
       "      <td>-0.576330</td>\n",
       "      <td>-0.507051</td>\n",
       "      <td>-0.716281</td>\n",
       "      <td>-0.573016</td>\n",
       "      <td>-0.623524</td>\n",
       "      <td>-0.713250</td>\n",
       "      <td>-0.414172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>-0.115697</td>\n",
       "      <td>1.059131</td>\n",
       "      <td>0.583768</td>\n",
       "      <td>-0.293875</td>\n",
       "      <td>0.527452</td>\n",
       "      <td>0.691676</td>\n",
       "      <td>-0.052087</td>\n",
       "      <td>0.410897</td>\n",
       "      <td>0.046137</td>\n",
       "      <td>0.737526</td>\n",
       "      <td>...</td>\n",
       "      <td>2.517924</td>\n",
       "      <td>3.742895</td>\n",
       "      <td>3.391589</td>\n",
       "      <td>0.305562</td>\n",
       "      <td>0.104015</td>\n",
       "      <td>0.160366</td>\n",
       "      <td>-0.235124</td>\n",
       "      <td>0.201521</td>\n",
       "      <td>1.091970</td>\n",
       "      <td>0.155848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512</th>\n",
       "      <td>-0.183097</td>\n",
       "      <td>0.716132</td>\n",
       "      <td>0.258574</td>\n",
       "      <td>-0.420926</td>\n",
       "      <td>0.113760</td>\n",
       "      <td>0.450778</td>\n",
       "      <td>-0.237647</td>\n",
       "      <td>0.160923</td>\n",
       "      <td>-0.077343</td>\n",
       "      <td>0.466684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530899</td>\n",
       "      <td>1.000613</td>\n",
       "      <td>0.895689</td>\n",
       "      <td>0.052787</td>\n",
       "      <td>-0.114444</td>\n",
       "      <td>0.007075</td>\n",
       "      <td>-0.462386</td>\n",
       "      <td>-0.039817</td>\n",
       "      <td>0.773744</td>\n",
       "      <td>-0.054653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513</th>\n",
       "      <td>-0.183720</td>\n",
       "      <td>0.696043</td>\n",
       "      <td>0.269436</td>\n",
       "      <td>-0.401614</td>\n",
       "      <td>0.077996</td>\n",
       "      <td>0.506875</td>\n",
       "      <td>-0.108806</td>\n",
       "      <td>0.183974</td>\n",
       "      <td>-0.030824</td>\n",
       "      <td>0.535118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126830</td>\n",
       "      <td>-0.057985</td>\n",
       "      <td>-0.049533</td>\n",
       "      <td>-0.042148</td>\n",
       "      <td>-0.045282</td>\n",
       "      <td>0.017888</td>\n",
       "      <td>-0.357489</td>\n",
       "      <td>0.067339</td>\n",
       "      <td>0.832164</td>\n",
       "      <td>-0.098938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3514</th>\n",
       "      <td>-0.144083</td>\n",
       "      <td>0.481942</td>\n",
       "      <td>0.191978</td>\n",
       "      <td>-0.412277</td>\n",
       "      <td>0.165111</td>\n",
       "      <td>0.442213</td>\n",
       "      <td>-0.115928</td>\n",
       "      <td>0.194667</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.544686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.344364</td>\n",
       "      <td>-0.323794</td>\n",
       "      <td>-0.296564</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>0.174514</td>\n",
       "      <td>0.168020</td>\n",
       "      <td>-0.398325</td>\n",
       "      <td>-0.001075</td>\n",
       "      <td>0.757593</td>\n",
       "      <td>-0.133510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>-0.184202</td>\n",
       "      <td>0.460728</td>\n",
       "      <td>0.058034</td>\n",
       "      <td>-0.498039</td>\n",
       "      <td>-0.058153</td>\n",
       "      <td>0.255827</td>\n",
       "      <td>-0.299355</td>\n",
       "      <td>0.039648</td>\n",
       "      <td>-0.178863</td>\n",
       "      <td>0.307367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290732</td>\n",
       "      <td>-0.279300</td>\n",
       "      <td>-0.262389</td>\n",
       "      <td>0.027223</td>\n",
       "      <td>-0.083787</td>\n",
       "      <td>-0.050927</td>\n",
       "      <td>-0.418211</td>\n",
       "      <td>-0.125951</td>\n",
       "      <td>0.611293</td>\n",
       "      <td>-0.218080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3516 rows × 3129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      -95.35  28.85 \\n  -103.593750  34.656250\\n  -103.531250  34.656250\\n  \\\n",
       "0             9.911094                 -0.134267                 -0.398994   \n",
       "1             0.035373                 -0.726517                 -0.466346   \n",
       "2            -0.184683                 -0.176776                 -0.466799   \n",
       "3            -0.184683                 -0.387886                 -0.594697   \n",
       "4             0.019306                 -0.445776                 -0.633418   \n",
       "...                ...                       ...                       ...   \n",
       "3511         -0.115697                  1.059131                  0.583768   \n",
       "3512         -0.183097                  0.716132                  0.258574   \n",
       "3513         -0.183720                  0.696043                  0.269436   \n",
       "3514         -0.144083                  0.481942                  0.191978   \n",
       "3515         -0.184202                  0.460728                  0.058034   \n",
       "\n",
       "      -103.468750  34.656250\\n  -103.406250  34.656250\\n  \\\n",
       "0                     0.256755                 -0.383672   \n",
       "1                    -0.129167                 -0.578796   \n",
       "2                    -0.400074                 -0.427399   \n",
       "3                    -0.516747                 -0.469316   \n",
       "4                    -0.487968                 -0.469061   \n",
       "...                        ...                       ...   \n",
       "3511                 -0.293875                  0.527452   \n",
       "3512                 -0.420926                  0.113760   \n",
       "3513                 -0.401614                  0.077996   \n",
       "3514                 -0.412277                  0.165111   \n",
       "3515                 -0.498039                 -0.058153   \n",
       "\n",
       "      -103.343750  34.656250\\n  -103.281250  34.656250\\n  \\\n",
       "0                     1.572451                 -0.674415   \n",
       "1                     0.337814                 -0.375985   \n",
       "2                    -0.359177                 -0.275025   \n",
       "3                    -0.495481                 -0.543043   \n",
       "4                    -0.491576                 -0.560085   \n",
       "...                        ...                       ...   \n",
       "3511                  0.691676                 -0.052087   \n",
       "3512                  0.450778                 -0.237647   \n",
       "3513                  0.506875                 -0.108806   \n",
       "3514                  0.442213                 -0.115928   \n",
       "3515                  0.255827                 -0.299355   \n",
       "\n",
       "      -103.218750  34.656250\\n  -103.156250  34.656250\\n  \\\n",
       "0                    -0.228816                  0.037667   \n",
       "1                    -0.711423                 -0.462730   \n",
       "2                    -0.393831                 -0.511412   \n",
       "3                    -0.590618                 -0.496078   \n",
       "4                    -0.603027                 -0.560102   \n",
       "...                        ...                       ...   \n",
       "3511                  0.410897                  0.046137   \n",
       "3512                  0.160923                 -0.077343   \n",
       "3513                  0.183974                 -0.030824   \n",
       "3514                  0.194667                  0.011004   \n",
       "3515                  0.039648                 -0.178863   \n",
       "\n",
       "      -103.656250  34.593750\\n  ...  -95.531250  29.031250\\n  \\\n",
       "0                    -0.532050  ...                -0.178725   \n",
       "1                    -0.125976  ...                -0.337374   \n",
       "2                    -0.347567  ...                -0.329134   \n",
       "3                    -0.469463  ...                -0.337176   \n",
       "4                    -0.470457  ...                -0.337135   \n",
       "...                        ...  ...                      ...   \n",
       "3511                  0.737526  ...                 2.517924   \n",
       "3512                  0.466684  ...                 0.530899   \n",
       "3513                  0.535118  ...                -0.126830   \n",
       "3514                  0.544686  ...                -0.344364   \n",
       "3515                  0.307367  ...                -0.290732   \n",
       "\n",
       "      -95.468750  29.031250\\n  -95.406250  29.031250\\n  \\\n",
       "0                   -0.230239                -0.252408   \n",
       "1                   -0.346014                -0.374297   \n",
       "2                   -0.343043                -0.378763   \n",
       "3                   -0.345840                -0.380737   \n",
       "4                   -0.345820                -0.381714   \n",
       "...                       ...                      ...   \n",
       "3511                 3.742895                 3.391589   \n",
       "3512                 1.000613                 0.895689   \n",
       "3513                -0.057985                -0.049533   \n",
       "3514                -0.323794                -0.296564   \n",
       "3515                -0.279300                -0.262389   \n",
       "\n",
       "      -95.531250  28.968750\\n  -95.468750  28.968750\\n  \\\n",
       "0                   -0.572311                 0.088742   \n",
       "1                   -0.734310                -0.044489   \n",
       "2                   -0.592142                -0.343849   \n",
       "3                   -0.606311                -0.482309   \n",
       "4                   -0.576330                -0.507051   \n",
       "...                       ...                      ...   \n",
       "3511                 0.305562                 0.104015   \n",
       "3512                 0.052787                -0.114444   \n",
       "3513                -0.042148                -0.045282   \n",
       "3514                 0.005189                 0.174514   \n",
       "3515                 0.027223                -0.083787   \n",
       "\n",
       "      -95.406250  28.968750\\n  -95.343750  28.968750\\n  \\\n",
       "0                    0.446975                -0.651768   \n",
       "1                    0.021120                -0.418514   \n",
       "2                   -0.497109                -0.257276   \n",
       "3                   -0.705154                -0.588362   \n",
       "4                   -0.716281                -0.573016   \n",
       "...                       ...                      ...   \n",
       "3511                 0.160366                -0.235124   \n",
       "3512                 0.007075                -0.462386   \n",
       "3513                 0.017888                -0.357489   \n",
       "3514                 0.168020                -0.398325   \n",
       "3515                -0.050927                -0.418211   \n",
       "\n",
       "      -95.468750  28.906250\\n  -95.406250  28.906250\\n  \\\n",
       "0                   -0.300383                 0.901711   \n",
       "1                   -0.612205                 0.086772   \n",
       "2                   -0.389134                -0.491061   \n",
       "3                   -0.593416                -0.691268   \n",
       "4                   -0.623524                -0.713250   \n",
       "...                       ...                      ...   \n",
       "3511                 0.201521                 1.091970   \n",
       "3512                -0.039817                 0.773744   \n",
       "3513                 0.067339                 0.832164   \n",
       "3514                -0.001075                 0.757593   \n",
       "3515                -0.125951                 0.611293   \n",
       "\n",
       "      -95.343750  28.906250\\n  \n",
       "0                    0.067492  \n",
       "1                   -0.196638  \n",
       "2                   -0.162036  \n",
       "3                   -0.405932  \n",
       "4                   -0.414172  \n",
       "...                       ...  \n",
       "3511                 0.155848  \n",
       "3512                -0.054653  \n",
       "3513                -0.098938  \n",
       "3514                -0.133510  \n",
       "3515                -0.218080  \n",
       "\n",
       "[3516 rows x 3129 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frame = pd.read_csv(\"C:/Users/psheth5/STCD-RL/data/data/watershed_avg.csv\")\n",
    "frame = pd.read_csv(\"C:/Users/psheth5/STCD-RL/data/data/StandardizedData.csv\")\n",
    "n_features = frame.shape[1]\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# adj_mat = np.load('C:/Users/psheth5/STCD-RL/data/data/watershed.npy')\n",
    "\n",
    "adj_mat = np.load('ElevationAdjacency.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # distances = np.load('C:/Users/psheth5/STCD-RL/distance.npy')\n",
    "# # np.fill_diagonal(distance, np.inf)\n",
    "# # distances[np.isfinite(distance)] = 1   # replace finite values with 1\n",
    "# # distances[~np.isfinite(distance)] = 0   # replace infinite values with 0\n",
    "# # distances\n",
    "\n",
    "# list_of_coords_str = frame.columns # your list of 3129 latitude longitude values\n",
    "# list_of_coords = [tuple(map(float, c.split()[::-1])) for c in list_of_coords_str]\n",
    "# adj_matrix_list = np.zeros((len(list_of_coords), len(frame.columns)))\n",
    "# for i, c1 in enumerate(list_of_coords):\n",
    "#     for j, c2 in enumerate(list_of_coords):\n",
    "#         if c2[0] > c1[0] and distance(c1, c2).km > 0:\n",
    "#             adj_matrix_list[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adj_mat = np.load('C:/Users/psheth5/STCD-RL/data/data/watershed.npy')\n",
    "# coo = coo_matrix(adj_matrix_list, dtype = \"int8\")\n",
    "coo = coo_matrix(adj_mat, dtype = \"int8\")\n",
    "row = torch.from_numpy(coo.row.astype(np.int64)).to(torch.long)\n",
    "col = torch.from_numpy(coo.col.astype(np.int64)).to(torch.long)\n",
    "edge_index = torch.stack([row, col], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"data\\\\data\\\\adj_mat_new.npy\", adj_matrix_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def filter_edge_index(edge_index, coords):\n",
    "    filtered_index = []\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        u = edge_index[0][i]\n",
    "        v = edge_index[1][i]\n",
    "        # check if u is above v\n",
    "        if torch.tensor(coords[u][0]) > torch.tensor(coords[v][0]) and u != v:\n",
    "            filtered_index.append([u, v])\n",
    "    filtered_index = np.array(filtered_index).T\n",
    "    return filtered_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index = filter_edge_index(edge_index, list_of_coords)\n",
    "# edge_index = torch.from_numpy(edge_index.astype(np.int64)).to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping function\n",
    "def map_values(value, value_range):\n",
    "    \"\"\"Maps a value from the input range to the output range.\"\"\"\n",
    "    input_min, input_max = value_range\n",
    "    output_min, output_max = (0, 99)\n",
    "    return torch.floor(((value - input_min) / (input_max - input_min)) * (output_max - output_min) + output_min).long()\n",
    "\n",
    "\n",
    "def reverse_map_values(mapped_value, value_range):\n",
    "    \"\"\"Maps a value from the output range to the input range.\"\"\"\n",
    "    input_min, input_max = value_range\n",
    "    output_min, output_max = (0, 99)\n",
    "    return torch.floor(((mapped_value - output_min) / (output_max - output_min)) * (input_max - input_min) + input_min).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tasks(Enum):\n",
    "    prediction = \"prediction\"\n",
    "    reconstruction = \"reconstruction\"\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(object):\n",
    "    def __init__(self, task: Tasks, data_path: str, categorical_cols: List[str], index_col: str, target_col: str,\n",
    "                 seq_length: int, batch_size: int, prediction_window: int = 1):\n",
    "        \"\"\"\n",
    "        :param task: name of the task\n",
    "        :param data_path: path to datafile\n",
    "        :param categorical_cols: name of the categorical columns, if None pass empty list\n",
    "        :param index_col: column to use as index\n",
    "        :param target_col: name of the targeted column\n",
    "        :param seq_length: window length to use\n",
    "        :param batch_size:\n",
    "        :param prediction_window: window length to predict\n",
    "        \"\"\"\n",
    "        self.task = task.value\n",
    "\n",
    "        \n",
    "\n",
    "        # data_path = pkg_resources.resource_filename(\"tsa\", data_path)\n",
    "        self.data = pd.read_csv(data_path, index_col=index_col)[0:1460]\n",
    "        # a  = [self.data.columns[0]]\n",
    "        # a.extend(self.data.columns[-250:])\n",
    "        # self.data = self.data[a]\n",
    "        self.categorical_cols = categorical_cols\n",
    "        # self.numerical_cols = list(set(self.data.columns) - set(categorical_cols) - set(target_col))\n",
    "        self.numerical_cols = self.data.columns\n",
    "        print(len(self.numerical_cols))\n",
    "        self.target_col = target_col\n",
    "\n",
    "        self.seq_length = seq_length\n",
    "        self.prediction_window = prediction_window\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        transformations = [(\"scaler\", StandardScaler(), self.numerical_cols)]\n",
    "        if len(self.categorical_cols) > 0:\n",
    "            transformations.append((\"encoder\", OneHotEncoder(), self.categorical_cols))\n",
    "        self.preprocessor = ColumnTransformer(transformations, remainder=\"passthrough\")\n",
    "\n",
    "        if self.task == \"prediction\":\n",
    "            self.y_scaler = StandardScaler()\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Preprocessing function\"\"\"\n",
    "        X = self.data#.drop(self.target_col, axis=1,inplace=False)\n",
    "        # y = self.data[self.target_col]\n",
    "\n",
    "        X_train, X_test = train_test_split(X,train_size=0.8, shuffle=False)\n",
    "        X_train = self.preprocessor.fit_transform(X_train)\n",
    "        X_test = self.preprocessor.transform(X_test)\n",
    "\n",
    "        # if self.task == \"prediction\":\n",
    "        #     y_train = self.y_scaler.fit_transform([y_train])\n",
    "        #     y_test = self.y_scaler.fit_transform([y_test])\n",
    "        #     return X_train, X_test, y_train.reshape(-1,1), y_test.reshape(-1,1)\n",
    "        return X_train, X_test, None,None\n",
    "\n",
    "    def frame_series(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Function used to prepare the data for time series prediction\n",
    "        :param X: set of features\n",
    "        :param y: targeted value to predict\n",
    "        :return: TensorDataset\n",
    "        \"\"\"\n",
    "        nb_obs, nb_features = X.shape\n",
    "        features, target, y_hist = [], [], []\n",
    "\n",
    "        for i in range(1, nb_obs - self.seq_length - self.prediction_window):\n",
    "            features.append(torch.FloatTensor(X[i:i + self.seq_length, :]).unsqueeze(0))\n",
    "\n",
    "            if self.task == \"prediction\":\n",
    "                # lagged output used for prediction\n",
    "                y_hist.append(torch.FloatTensor(y[i - 1:i + self.seq_length - 1]).unsqueeze(0))\n",
    "                # shifted target\n",
    "                target.append(torch.FloatTensor(y[i + self.seq_length:i + self.seq_length + self.prediction_window]).unsqueeze(0))\n",
    "            else:\n",
    "                y_hist.append(torch.FloatTensor(X[i - 1: i + self.seq_length - 1, :]).unsqueeze(0))\n",
    "                target.append(\n",
    "                    torch.FloatTensor(X[i + self.seq_length:i + self.seq_length + self.prediction_window, :]))\n",
    "\n",
    "        features_var = torch.cat(features)\n",
    "        y_hist_var = torch.cat(y_hist)\n",
    "        target_var = torch.cat(target)\n",
    "\n",
    "        return TensorDataset(features_var, y_hist_var, target_var)\n",
    "\n",
    "    def get_loaders(self):\n",
    "        \"\"\"\n",
    "        Preprocess and frame the dataset\n",
    "\n",
    "        :return: DataLoaders associated to training and testing data\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = self.preprocess_data()\n",
    "        nb_features = X_train.shape[1]\n",
    "\n",
    "        train_dataset = self.frame_series(X_train, y_train)\n",
    "        test_dataset = self.frame_series(X_test, y_test)\n",
    "\n",
    "        train_iter = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "        test_iter = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "        return train_iter, test_iter, nb_features\n",
    "\n",
    "    def invert_scale(self, predictions):\n",
    "        \"\"\"\n",
    "        Inverts the scale of the predictions\n",
    "        \"\"\"\n",
    "        if isinstance(predictions, torch.Tensor):\n",
    "            predictions = predictions.numpy()\n",
    "\n",
    "        if predictions.ndim == 1:\n",
    "            predictions = predictions.reshape(-1, 1)\n",
    "\n",
    "        if self.task == \"prediction\":\n",
    "            unscaled = self.y_scaler.inverse_transform(predictions)\n",
    "        else:\n",
    "            unscaled = self.preprocessor.named_transformers_[\"scaler\"].inverse_transform(predictions)\n",
    "        return torch.Tensor(unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3129\n"
     ]
    }
   ],
   "source": [
    "task = Tasks('reconstruction')\n",
    "data1 = TimeSeriesDataset(task=task,data_path=\"C:/Users/psheth5/STCD-RL/data/data/StandardizedData.csv\",categorical_cols=[],index_col=None,target_col=frame.columns[0],seq_length=30,batch_size=256,prediction_window=1)\n",
    "train_iter, test_iter, nb_features = data1.get_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "def init_hidden(x: torch.Tensor, hidden_size: int, num_dir: int = 1, xavier: bool = True):\n",
    "    \"\"\"\n",
    "    Initialize hidden.\n",
    "\n",
    "    Args:\n",
    "        x: (torch.Tensor): input tensor\n",
    "        hidden_size: (int):\n",
    "        num_dir: (int): number of directions in LSTM\n",
    "        xavier: (bool): wether or not use xavier initialization\n",
    "    \"\"\"\n",
    "    if xavier:\n",
    "        return nn.init.xavier_normal_(torch.zeros(num_dir, x.size(0), hidden_size)).to(device)\n",
    "    return Variable(torch.zeros(num_dir, x.size(0), hidden_size)).to(device)\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "################################ ENCODERS #################################\n",
    "###########################################################################\n",
    "class AttnEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size_encoder,seq_len,denoising,directions,input_size,edge_index,spatial,use_spatial=False):\n",
    "        \"\"\"\n",
    "        Initialize the network.\n",
    "\n",
    "        Args:\n",
    "            config:\n",
    "            input_size: (int): size of the input\n",
    "        \"\"\"\n",
    "        super(AttnEncoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size_encoder\n",
    "        self.seq_len = seq_len\n",
    "        self.add_noise = denoising\n",
    "        self.gcn_e = GCNConv(in_channels=-1, out_channels=self.hidden_size)\n",
    "        self.directions = directions\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=1\n",
    "        )\n",
    "        self.attn = nn.Linear(\n",
    "            in_features=2 * self.hidden_size + self.seq_len,\n",
    "            out_features=1\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.edge_index=edge_index\n",
    "        self.use_spatial = use_spatial\n",
    "        self.spatial_mat = spatial\n",
    "\n",
    "    def forward(self, input_data: torch.Tensor,sample:torch.Tensor):\n",
    "        \"\"\"\n",
    "        Forward computation.\n",
    "\n",
    "        Args:\n",
    "            input_data: (torch.Tensor): tensor of input data\n",
    "        \"\"\"\n",
    "        spatial = self.spatial_mat[sample]\n",
    "        spatial = spatial.to(device)\n",
    "        h_t, c_t = (init_hidden(input_data, self.hidden_size, num_dir=self.directions),\n",
    "                    init_hidden(input_data, self.hidden_size, num_dir=self.directions))\n",
    "\n",
    "        # apply the mapping function to the sampled tensor\n",
    "        a = self.edge_index[0][sample]\n",
    "        b = self.edge_index[1][sample]\n",
    "        sample_edge_index = torch.stack([a, b], dim=0)\n",
    "        mapped_arr = map_values(sample_edge_index, (sample_edge_index.min(), sample_edge_index.max()))\n",
    "        \n",
    "        attentions, input_encoded = (Variable(torch.zeros(input_data.size(0), self.seq_len, self.input_size)),\n",
    "                                     Variable(torch.zeros(input_data.size(0), self.seq_len, self.hidden_size)))\n",
    "\n",
    "        if self.add_noise and self.training:\n",
    "            input_data += self._get_noise(input_data).to(device)\n",
    "        \n",
    "        for t in range(self.seq_len):\n",
    "            x = torch.cat((h_t.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
    "                           c_t.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
    "                           input_data.permute(0, 2, 1).to(device)), dim=2).to(\n",
    "                device)  # bs * input_size * (2 * hidden_dim + seq_len)\n",
    "\n",
    "            e_t = self.attn(x.view(-1, self.hidden_size * 2 + self.seq_len))  # (bs * input_size) * 1\n",
    "            a_t = self.softmax(e_t.view(-1, self.input_size)).to(device)  # (bs, input_size)\n",
    "            weighted_input = torch.mul(a_t, input_data[:, t, :].to(device))  # (bs * input_size)\n",
    "            self.lstm.flatten_parameters()\n",
    "            _, (h_t, c_t) = self.lstm(weighted_input.unsqueeze(0), (h_t, c_t))\n",
    "\n",
    "            if(self.use_spatial):\n",
    "                h_t = self.gcn_e(h_t,mapped_arr.to(device))\n",
    "            input_encoded[:, t, :] = h_t\n",
    "            attentions[:, t, :] = a_t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return attentions, input_encoded\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "################################ DECODERS #################################\n",
    "###########################################################################\n",
    "\n",
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, seq_len,hidden_size_encoder,hidden_size_decoder,output_size,edge_index):\n",
    "        \"\"\"\n",
    "        Initialize the network.\n",
    "\n",
    "        Args:\n",
    "            config:\n",
    "        \"\"\"\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.encoder_hidden_size = hidden_size_encoder\n",
    "        self.decoder_hidden_size = hidden_size_decoder\n",
    "        self.out_feats = output_size\n",
    "\n",
    "        self.gcn_d = GCNConv(in_channels=-1, out_channels=self.decoder_hidden_size)\n",
    "\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(2 * self.decoder_hidden_size + self.encoder_hidden_size, self.encoder_hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.encoder_hidden_size, 1)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(input_size=self.out_feats, hidden_size=self.decoder_hidden_size)\n",
    "        self.fc = nn.Linear(self.encoder_hidden_size + self.out_feats, self.out_feats)\n",
    "        self.fc_out = nn.Linear(self.decoder_hidden_size + self.encoder_hidden_size, self.out_feats)\n",
    "        self.fc.weight.data.normal_()\n",
    "        self.edge_index = edge_index\n",
    "    \n",
    "\n",
    "    def forward(self, input_encoded: torch.Tensor, y_history: torch.Tensor, sample: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Perform forward computation.\n",
    "\n",
    "        Args:\n",
    "            input_encoded: (torch.Tensor): tensor of encoded input\n",
    "            y_history: (torch.Tensor): shifted target\n",
    "        \"\"\"\n",
    "        h_t, c_t = (init_hidden(input_encoded, self.decoder_hidden_size), init_hidden(input_encoded, self.decoder_hidden_size))\n",
    "        context = Variable(torch.zeros(input_encoded.size(0), self.encoder_hidden_size))\n",
    "\n",
    "        a = self.edge_index[0][sample]\n",
    "        b = self.edge_index[1][sample]\n",
    "        sample_edge_index = torch.stack([a, b], dim=0)\n",
    "        mapped_arr = map_values(sample_edge_index, (sample_edge_index.min(), sample_edge_index.max()))\n",
    "\n",
    "        for t in range(self.seq_len):\n",
    "            x = torch.cat((h_t.repeat(self.seq_len, 1, 1).permute(1, 0, 2),\n",
    "                           c_t.repeat(self.seq_len, 1, 1).permute(1, 0, 2),\n",
    "                           input_encoded.to(device)), dim=2)\n",
    "            x = tf.softmax(\n",
    "                self.attn(\n",
    "                    x.view(-1, 2 * self.decoder_hidden_size + self.encoder_hidden_size)\n",
    "                ).view(-1, self.seq_len),\n",
    "                dim=1)\n",
    "            context = torch.bmm(x.unsqueeze(1), input_encoded.to(device))[:, 0, :]  # (batch_size, encoder_hidden_size)\n",
    "            y_tilde = self.fc(torch.cat((context.to(device), y_history[:, t].to(device)),\n",
    "                                        dim=1))  # (batch_size, out_size)            \n",
    "            self.lstm.flatten_parameters()\n",
    "            _, (h_t, c_t) = self.lstm(y_tilde.unsqueeze(0), (h_t, c_t))\n",
    "            h_t = self.gcn_d(h_t,mapped_arr.to(device))\n",
    "        \n",
    "\n",
    "        return self.fc_out(torch.cat((h_t[0], context.to(device)), dim=1))  # predicting value at t=self.seq_length+1\n",
    "\n",
    "\n",
    "class AutoEncForecast(nn.Module):\n",
    "    def __init__(self, input_att,temporal_att,hidden_size_encoder,seq_len,denoising,directions,hidden_size_decoder,input_size,output_size,sample_size,edge_index,spatial_matrix,use_spatial=False):\n",
    "        \"\"\"\n",
    "        Initialize the network.\n",
    "\n",
    "        Args:\n",
    "            config:\n",
    "            input_size: (int): size of the input\n",
    "        \"\"\"\n",
    "        super(AutoEncForecast, self).__init__()\n",
    "        self.encoder = AttnEncoder(hidden_size_encoder,seq_len,denoising,directions,input_size,edge_index,spatial_matrix,use_spatial).to(device) if input_att else \\\n",
    "            Encoder(hidden_size_encoder, seq_len, input_size,edge_index).to(device)\n",
    "        self.decoder = AttnDecoder(seq_len,hidden_size_encoder,hidden_size_decoder,output_size,edge_index).to(device) if temporal_att else Decoder(seq_len,hidden_size_decoder,output_size,edge_index).to(device)\n",
    "\n",
    "        self.fc1 = nn.Linear(256,1)#.cuda()\n",
    "        self.tanh = nn.Tanh()#.cuda()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "    def calcPerm(self,l: list, m: int):\n",
    "        for i in permutations(l, m):\n",
    "            yield list((i))\n",
    "    \n",
    "    def forward(self, encoder_input: torch.Tensor, y_hist: torch.Tensor, sample: torch.Tensor ,return_attention: bool = False):\n",
    "        \"\"\"\n",
    "        Forward computation. encoder_input_inputs.\n",
    "\n",
    "        Args:\n",
    "            encoder_input: (torch.Tensor): tensor of input data\n",
    "            y_hist: (torch.Tensor): shifted target\n",
    "            return_attention: (bool): whether or not to return the attention\n",
    "        \"\"\"\n",
    "        attentions, encoder_output = self.encoder(encoder_input, sample)   \n",
    "\n",
    "        outputs = self.decoder(encoder_output, y_hist.float(), sample)\n",
    "        g = torch.zeros(outputs.shape[1],outputs.shape[1])#.cuda()\n",
    "        outputs = outputs.transpose(1,0)\n",
    "        idx1 = 0\n",
    "        idx2 = 0\n",
    "        for i,j in self.calcPerm(outputs, 2):\n",
    "                a = self.fc1(i)\n",
    "                b = self.fc1(j)\n",
    "                c = self.sigmoid(self.tanh(a+b))#.cuda()\n",
    "                g[idx1,idx2] = c\n",
    "                if((idx2+1)%self.sample_size):\n",
    "                    idx2+=1\n",
    "                else:\n",
    "                    idx2 = 0\n",
    "                    idx1+= 1\n",
    "        if return_attention:\n",
    "            return outputs, attentions,g\n",
    "        return outputs,g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_index = 252\n",
    "target_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distance = np.load('C:/Users/psheth5/STCD-RL/data/data/watershed.npy')\n",
    "# distance = distance[:, target_index]\n",
    "\n",
    "# spatial_matrix = []\n",
    "\n",
    "# for d in distance:\n",
    "#     if np.isfinite(d):\n",
    "#         spatial_matrix.append(1 / (d + 1))\n",
    "#     else:\n",
    "#         spatial_matrix.append(0)\n",
    "\n",
    "# spatial_matrix1 = torch.FloatTensor(spatial_matrix).cuda()\n",
    "# torch.max(spatial_matrix1)\n",
    "\n",
    "spatial_matrix1 = torch.FloatTensor(adj_mat).cuda()\n",
    "torch.max(spatial_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_size = 100\n",
    "model = AutoEncForecast(input_att=True,temporal_att=True,hidden_size_encoder=64,seq_len=30,denoising=False,directions=1,hidden_size_decoder=64,input_size=sampling_size,output_size=sampling_size,sample_size=sampling_size,edge_index=edge_index,spatial_matrix = spatial_matrix1,use_spatial=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def update_graph(sample,inferred_cg,g):\n",
    "    for i in range(len(sample)):\n",
    "        for j in range(len(sample)):\n",
    "            inferred_cg[sample[i],sample[j]] += g[i,j].cpu()\n",
    "    return inferred_cg\n",
    "\n",
    "def update_attention(sample,att,attention):\n",
    "    temp = torch.mean(att,axis=1)\n",
    "    for i in range(len(sample)):\n",
    "        for j in range(len(sample)):\n",
    "            attention[sample[i],sample[j]] += temp[i,j].cpu()\n",
    "    return attention\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def get_num_cycles(gra):\n",
    "    # gra = gra.cpu().detach().numpy()\n",
    "    G = nx.from_numpy_matrix(gra)\n",
    "    H = G.to_directed()\n",
    "    try:\n",
    "        return torch.FloatTensor([len(list(nx.find_cycle(H, orientation=\"original\")))])#.cuda()\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def is_dag(gr):\n",
    "    # gr = gr.cpu().detach().numpy()\n",
    "    G = nx.from_numpy_matrix(gr)\n",
    "    return int(nx.is_directed_acyclic_graph(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions\n",
    "def calc_discounted_rewards(rewards, gamma):\n",
    "    ''' \n",
    "    Simple implementation for better understanding\n",
    "    gets rewards of an entire episode and calculates R_t for every t\n",
    "    '''\n",
    "    \n",
    "    returns = []\n",
    "    \n",
    "    for t in range(len(rewards)):\n",
    "        ret = 0\n",
    "        \n",
    "        for t_p in range(t, len(rewards)):\n",
    "            ret += gamma ** (t_p - t) * rewards[t_p]\n",
    "            \n",
    "        returns.insert(0, ret)\n",
    "        \n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?epoch/s]\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [01:12<03:38, 72.77s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [03:14<03:23, 101.68s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [05:52<02:07, 127.19s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [09:01<00:00, 151.68s/batch]\u001b[A\r100%|██████████| 4/4 [09:01<00:00, 135.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  17.031532287597656  for epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [09:52<8:04:15, 592.96s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    7,    8,   11,   13,   15,   18,   20,   36,   42,   43,\n",
      "         52,   54,   56,   58,   59,   61,   71,   72,   73,   93,  107,\n",
      "        109,  111,  113,  118,  121,  134,  139,  142,  146,  148,  149,\n",
      "        151,  153,  156,  162,  179,  182,  187,  190,  198,  199,  211,\n",
      "        219,  221,  227,  231,  237,  240,  250,  255,  258,  259,  265,\n",
      "        268,  272,  274,  279,  281,  289,  291,  302,  306,  307,  308,\n",
      "        309,  311,  313,  323,  328,  332,  336,  338,  342,  344,  346,\n",
      "        352,  354,  355,  356,  358,  360,  366,  367,  372,  376,  384,\n",
      "        400,  401,  404,  413,  421,  425,  433,  445,  456,  458,  468,\n",
      "        471,  480,  482,  486,  499,  505,  506,  510,  516,  532,  543,\n",
      "        549,  552,  554,  555,  558,  559,  561,  562,  563,  570,  573,\n",
      "        575,  579,  581,  586,  591,  597,  600,  606,  614,  625,  627,\n",
      "        641,  644,  649,  653,  656,  664,  666,  667,  668,  669,  671,\n",
      "        679,  682,  684,  686,  696,  701,  702,  707,  719,  720,  722,\n",
      "        723,  732,  735,  736,  743,  750,  752,  755,  758,  765,  768,\n",
      "        769,  771,  773,  774,  779,  785,  789,  791,  793,  796,  799,\n",
      "        801,  808,  811,  814,  816,  818,  819,  836,  838,  841,  845,\n",
      "        849,  852,  853,  859,  861,  863,  877,  878,  880,  882,  888,\n",
      "        891,  897,  918,  923,  925,  927,  932,  934,  935,  940,  943,\n",
      "        944,  945,  950,  966,  973,  975,  977,  978,  980,  982,  984,\n",
      "        985,  987,  995,  998,  999, 1001, 1002, 1004, 1006, 1014, 1016,\n",
      "       1022, 1027, 1028, 1037, 1039, 1042, 1043, 1047, 1049, 1051, 1054,\n",
      "       1058, 1059, 1063, 1065, 1067, 1071, 1075, 1077, 1079, 1081, 1084,\n",
      "       1088, 1090, 1093, 1095, 1097, 1104, 1123, 1125, 1126, 1132, 1136,\n",
      "       1137, 1143, 1144, 1145, 1146, 1148, 1149, 1152, 1161, 1165, 1168,\n",
      "       1169, 1173, 1184, 1185, 1205, 1212, 1215, 1221, 1223, 1226, 1243,\n",
      "       1248, 1249, 1260, 1262, 1272, 1275, 1278, 1280, 1291, 1295, 1298,\n",
      "       1311, 1316, 1318, 1321, 1323, 1324, 1330, 1333, 1349, 1351, 1355,\n",
      "       1367, 1374, 1378, 1382, 1388, 1393, 1395, 1397, 1398, 1399, 1404,\n",
      "       1408, 1413, 1415, 1418, 1420, 1421, 1427, 1428, 1430, 1439, 1443,\n",
      "       1447, 1449, 1450, 1457, 1458, 1463, 1465, 1466, 1474, 1477, 1481,\n",
      "       1483, 1484, 1486, 1489, 1496, 1497, 1498, 1502, 1505, 1511, 1513,\n",
      "       1517, 1518, 1519, 1523, 1526, 1527, 1529, 1532, 1535, 1538, 1539,\n",
      "       1541, 1543, 1545, 1551, 1552, 1556, 1566, 1569, 1570, 1582, 1585,\n",
      "       1586, 1590, 1595, 1596, 1600, 1601, 1614, 1621, 1628, 1632, 1638,\n",
      "       1646, 1654, 1658, 1659, 1680, 1685, 1689, 1692, 1696, 1705, 1706,\n",
      "       1707, 1708, 1710, 1715, 1725, 1730, 1731, 1737, 1740, 1741, 1742,\n",
      "       1745, 1748, 1750, 1761, 1763, 1769, 1774, 1775, 1783, 1788, 1790,\n",
      "       1794, 1795, 1802, 1803, 1812, 1820, 1825, 1830, 1833, 1840, 1841,\n",
      "       1849, 1854, 1866, 1871, 1879, 1891, 1897, 1899, 1901, 1912, 1926,\n",
      "       1943, 1957, 1959, 1965, 1967, 1968, 1970, 1975, 1976, 1987, 1988,\n",
      "       1993, 1994, 1995, 2004, 2007, 2008, 2011, 2016, 2019, 2021, 2023,\n",
      "       2025, 2029, 2031, 2032, 2033, 2035, 2046, 2057, 2063, 2069, 2072,\n",
      "       2074, 2079, 2085, 2088, 2096, 2097, 2098, 2103, 2107, 2108, 2110,\n",
      "       2116, 2117, 2118, 2120, 2122, 2127, 2130, 2132, 2133, 2139, 2141,\n",
      "       2148, 2152, 2158, 2160, 2164, 2170, 2175, 2179, 2199, 2200, 2201,\n",
      "       2202, 2205, 2212, 2214, 2219, 2224, 2226, 2227, 2231, 2232, 2242,\n",
      "       2244, 2251, 2252, 2253, 2255, 2259, 2261, 2267, 2270, 2275, 2277,\n",
      "       2285, 2295, 2300, 2303, 2306, 2310, 2313, 2316, 2321, 2323, 2328,\n",
      "       2333, 2334, 2339, 2341, 2342, 2347, 2348, 2349, 2352, 2354, 2361,\n",
      "       2372, 2377, 2380, 2382, 2389, 2392, 2401, 2412, 2414, 2417, 2420,\n",
      "       2422, 2425, 2429, 2430, 2433, 2435, 2438, 2439, 2449, 2455, 2456,\n",
      "       2457, 2464, 2468, 2473, 2476, 2485, 2488, 2489, 2492, 2497, 2504,\n",
      "       2513, 2514, 2515, 2516, 2517, 2519, 2521, 2522, 2527, 2537, 2546,\n",
      "       2561, 2562, 2566, 2591, 2592, 2594, 2595, 2596, 2600, 2610, 2614,\n",
      "       2616, 2620, 2621, 2632, 2633, 2636, 2637, 2642, 2644, 2645, 2646,\n",
      "       2647, 2651, 2652, 2660, 2661, 2664, 2670, 2676, 2681, 2685, 2697,\n",
      "       2698, 2699, 2703, 2704, 2713, 2714, 2717, 2721, 2722, 2723, 2726,\n",
      "       2728, 2736, 2737, 2738, 2739, 2742, 2746, 2767, 2771, 2781, 2784,\n",
      "       2787, 2788, 2792, 2793, 2796, 2804, 2805, 2807, 2811, 2812, 2814,\n",
      "       2815, 2816, 2821, 2822, 2828, 2829, 2832, 2839, 2841, 2843, 2851,\n",
      "       2864, 2865, 2870, 2871, 2881, 2885, 2887, 2892, 2898, 2908, 2909,\n",
      "       2921, 2922, 2928, 2929, 2937, 2940, 2941, 2950, 2957, 2958, 2959,\n",
      "       2963, 2966, 2975, 2983, 2993, 2997, 3000, 3005, 3010, 3013, 3027,\n",
      "       3033, 3036, 3039, 3042, 3051, 3053, 3055, 3075, 3091, 3104, 3107,\n",
      "       3111, 3112, 3113, 3123], dtype=int64),) 719 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [03:50<11:30, 230.26s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [08:21<08:28, 254.17s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [13:22<04:35, 275.82s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [19:00<00:00, 300.27s/batch]\u001b[A\r100%|██████████| 4/4 [19:00<00:00, 285.13s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  -59.857391357421875  for epoch  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [29:49<12:38:20, 947.92s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    7,    8, ..., 3124, 3125, 3127], dtype=int64),) 1253 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [08:53<26:40, 533.63s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [20:27<20:55, 627.60s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [32:49<11:19, 679.93s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [42:15<00:00, 634.96s/batch]\u001b[A\r100%|██████████| 4/4 [42:15<00:00, 633.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  26.762468338012695  for epoch  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [1:13:03<22:11:11, 1699.39s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    4,    7, ..., 3124, 3125, 3127], dtype=int64),) 1683 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [08:33<25:39, 513.02s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [17:03<17:02, 511.47s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [26:43<09:02, 542.80s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [37:29<00:00, 583.58s/batch]\u001b[A\r100%|██████████| 4/4 [37:29<00:00, 562.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  -18.119258880615234  for epoch  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [1:51:35<24:48:21, 1941.33s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    2,    4, ..., 3125, 3127, 3128], dtype=int64),) 2020 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [14:10<42:32, 850.90s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [30:39<31:03, 931.77s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [49:00<16:49, 1009.07s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [1:08:16<00:00, 1067.22s/batch]\u001b[A\r100%|██████████| 4/4 [1:08:16<00:00, 1024.18s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  -37.74992370605469  for epoch  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [3:01:29<34:25:14, 2753.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2, ..., 3126, 3127, 3128], dtype=int64),) 2284 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [19:58<59:56, 1198.80s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [34:27<33:28, 1004.37s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [51:33<16:54, 1014.32s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [1:04:15<00:00, 914.98s/batch]\u001b[A\r100%|██████████| 4/4 [1:04:15<00:00, 963.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  -30.369354248046875  for epoch  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [4:06:59<38:32:38, 3153.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2, ..., 3126, 3127, 3128], dtype=int64),) 2462 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [14:02<42:06, 842.04s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [27:27<27:21, 820.78s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [40:50<13:32, 812.40s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [54:50<00:00, 823.18s/batch]\u001b[A\r100%|██████████| 4/4 [54:50<00:00, 822.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  -13.73912525177002  for epoch  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [5:03:20<38:33:31, 3228.17s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2, ..., 3126, 3127, 3128], dtype=int64),) 2602 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [14:54<44:44, 894.72s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [30:04<30:07, 903.60s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [44:41<14:51, 891.36s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [59:55<00:00, 900.46s/batch]\u001b[A\r100%|██████████| 4/4 [59:55<00:00, 898.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  10.6995849609375  for epoch  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [6:04:33<39:18:48, 3369.72s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2, ..., 3126, 3127, 3128], dtype=int64),) 2714 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [16:15<48:46, 975.55s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [32:48<32:51, 985.57s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [48:50<16:15, 975.04s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [1:06:47<00:00, 1015.14s/batch]\u001b[A\r100%|██████████| 4/4 [1:06:47<00:00, 1001.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  -50.349884033203125  for epoch  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [7:13:02<41:00:31, 3600.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2, ..., 3126, 3127, 3128], dtype=int64),) 2805 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [26:24<1:19:13, 1584.47s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [53:01<53:03, 1591.86s/batch]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [1:23:10<28:11, 1691.07s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [1:51:41<00:00, 1698.80s/batch]\u001b[A\r100%|██████████| 4/4 [1:51:41<00:00, 1675.34s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  14.535408020019531  for epoch  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [9:06:43<51:03:19, 4594.99s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2, ..., 3126, 3127, 3128], dtype=int64),) 2885 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [28:33<1:25:39, 1713.29s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [57:17<57:19, 1719.71s/batch]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [1:26:15<28:48, 1728.28s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [1:55:57<00:00, 1749.13s/batch]\u001b[A\r100%|██████████| 4/4 [1:55:57<00:00, 1739.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  -5.280763626098633  for epoch  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [11:04:43<58:01:04, 5355.51s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2, ..., 3126, 3127, 3128], dtype=int64),) 2933 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [29:44<1:29:13, 1784.40s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [59:50<59:53, 1797.00s/batch]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [1:30:08<30:06, 1806.74s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [2:00:48<00:00, 1819.69s/batch]\u001b[A\r100%|██████████| 4/4 [2:00:48<00:00, 1812.03s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  -24.32246208190918  for epoch  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [13:07:47<63:02:31, 5972.42s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2, ..., 3126, 3127, 3128], dtype=int64),) 2976 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [30:38<1:31:54, 1838.12s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [1:01:38<1:01:42, 1851.23s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [1:32:54<31:02, 1862.60s/batch]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [2:04:27<00:00, 1874.66s/batch]\u001b[A\r100%|██████████| 4/4 [2:04:27<00:00, 1866.96s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  -30.11471939086914  for epoch  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [15:14:19<66:25:34, 6463.09s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2, ..., 3126, 3127, 3128], dtype=int64),) 3008 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [31:46<1:35:19, 1906.65s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [1:03:47<1:03:49, 1914.78s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [1:36:00<32:03, 1923.49s/batch]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [2:08:19<00:00, 1929.39s/batch]\u001b[A\r100%|██████████| 4/4 [2:08:19<00:00, 1924.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  -57.12908935546875  for epoch  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [17:24:48<68:45:27, 6875.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2, ..., 3126, 3127, 3128], dtype=int64),) 3035 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [32:36<1:37:48, 1956.20s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [1:05:19<1:05:20, 1960.17s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [1:38:23<32:51, 1971.26s/batch]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [2:11:41<00:00, 1981.64s/batch]\u001b[A\r100%|██████████| 4/4 [2:11:41<00:00, 1975.29s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  -12.197127342224121  for epoch  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [19:38:49<70:15:41, 7226.90s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2, ..., 3126, 3127, 3128], dtype=int64),) 3056 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [33:22<1:40:06, 2002.12s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [1:06:04<1:05:58, 1979.03s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 75%|███████▌  | 3/4 [1:42:16<34:26, 2066.74s/batch]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r100%|██████████| 4/4 [2:14:48<00:00, 2021.63s/batch]\u001b[A\r100%|██████████| 4/4 [2:14:48<00:00, 2022.15s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  -29.857707977294922  for epoch  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [21:56:02<71:06:54, 7529.83s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2, ..., 3126, 3127, 3128], dtype=int64),) 3067 tensor([1.]) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r  0%|          | 0/4 [00:00<?, ?batch/s]\u001b[A\n",
      "\r 25%|██▌       | 1/4 [37:56<1:53:49, 2276.59s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r 50%|█████     | 2/4 [1:14:47<1:14:36, 2238.04s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes sampled are  3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [1:23:09<1:23:09, 2494.79s/batch]\n",
      "\r 32%|███▏      | 16/50 [23:19:12<49:33:18, 5247.00s/epoch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m loss2 \u001b[39m=\u001b[39m crit_mse(output,target)\n\u001b[0;32m     66\u001b[0m n \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor([feature\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]])\u001b[39m#.cuda()\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m*\u001b[39m(n\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39mlog(loss2) \u001b[39m+\u001b[39m reg_factor1\u001b[39m*\u001b[39mget_num_cycles(inferred_cg) \u001b[39m+\u001b[39m reg_factor2\u001b[39m*\u001b[39mis_dag(inferred_cg))\n\u001b[0;32m     68\u001b[0m loss_2\u001b[39m.\u001b[39mappend(loss2)\n\u001b[0;32m     69\u001b[0m loss_1\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "Cell \u001b[1;32mIn [15], line 21\u001b[0m, in \u001b[0;36mget_num_cycles\u001b[1;34m(gra)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_num_cycles\u001b[39m(gra):\n\u001b[0;32m     19\u001b[0m     \u001b[39m# gra = gra.cpu().detach().numpy()\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     G \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39mfrom_numpy_matrix(gra)\n\u001b[1;32m---> 21\u001b[0m     H \u001b[39m=\u001b[39m G\u001b[39m.\u001b[39;49mto_directed()\n\u001b[0;32m     22\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mFloatTensor([\u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(nx\u001b[39m.\u001b[39mfind_cycle(H, orientation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moriginal\u001b[39m\u001b[39m\"\u001b[39m)))])\u001b[39m#.cuda()\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\networkx\\classes\\graph.py:1634\u001b[0m, in \u001b[0;36mGraph.to_directed\u001b[1;34m(self, as_view)\u001b[0m\n\u001b[0;32m   1632\u001b[0m G\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mupdate(deepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph))\n\u001b[0;32m   1633\u001b[0m G\u001b[39m.\u001b[39madd_nodes_from((n, deepcopy(d)) \u001b[39mfor\u001b[39;00m n, d \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_node\u001b[39m.\u001b[39mitems())\n\u001b[1;32m-> 1634\u001b[0m G\u001b[39m.\u001b[39;49madd_edges_from(\n\u001b[0;32m   1635\u001b[0m     (u, v, deepcopy(data))\n\u001b[0;32m   1636\u001b[0m     \u001b[39mfor\u001b[39;49;00m u, nbrs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_adj\u001b[39m.\u001b[39;49mitems()\n\u001b[0;32m   1637\u001b[0m     \u001b[39mfor\u001b[39;49;00m v, data \u001b[39min\u001b[39;49;00m nbrs\u001b[39m.\u001b[39;49mitems()\n\u001b[0;32m   1638\u001b[0m )\n\u001b[0;32m   1639\u001b[0m \u001b[39mreturn\u001b[39;00m G\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\networkx\\classes\\digraph.py:748\u001b[0m, in \u001b[0;36mDiGraph.add_edges_from\u001b[1;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[0;32m    746\u001b[0m datadict\u001b[39m.\u001b[39mupdate(dd)\n\u001b[0;32m    747\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_succ[u][v] \u001b[39m=\u001b[39m datadict\n\u001b[1;32m--> 748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pred[v][u] \u001b[39m=\u001b[39m datadict\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "global_step, logging_loss = 0, 0.0\n",
    "train_loss = 0.0\n",
    "reg1= True\n",
    "reg2= True\n",
    "reg_factor1= 1e-2\n",
    "reg_factor2= 1e-2\n",
    "gradient_accumulation_steps = 1\n",
    "max_grad_norm = 0.1\n",
    "logging_steps = 100\n",
    "criterion = nn.BCELoss()\n",
    "crit_mse = nn.MSELoss()\n",
    "crit_nll = nn.NLLLoss()\n",
    "save_steps = 5000\n",
    "eval_during_training = False\n",
    "output_dir = \"Models\"\n",
    "lrs_step_size=5000\n",
    "do_eval=True\n",
    "reg_factor = 1\n",
    "BASELINE_REWARD = 20\n",
    "breakout = 0\n",
    "inferred_cg = np.zeros((n_features,n_features))\n",
    "attention = np.zeros((n_features,n_features))\n",
    "min_loss = 1e+5\n",
    "for epoch in tqdm(range(50), unit=\"epoch\"):\n",
    "    attentions = []\n",
    "    outputs = []\n",
    "    total_loss = 0\n",
    "    loss_1 = []\n",
    "    loss_2 = []\n",
    "    for i, batch in tqdm(enumerate(train_iter), total=len(train_iter), unit=\"batch\"):\n",
    "        original_list = list(range(3129))\n",
    "        while(len(original_list)!=0):\n",
    "            sampled_list = []\n",
    "            optimizer.zero_grad()\n",
    "            model.train()\n",
    "            feature, y_hist, target = batch\n",
    "            try:\n",
    "                sample = random.sample(original_list, sampling_size)\n",
    "            except:\n",
    "                sample = random.sample(original_list,len(original_list))\n",
    "                sample.extend(random.sample(range(feature.shape[2]),sampling_size-len(original_list)-1))\n",
    "                sample.append(0)\n",
    "            # add the sampled elements to the sampled list\n",
    "            sampled_list.extend(sample)\n",
    "            # remove the sampled elements from the original list\n",
    "            original_list = [element for element in original_list if element not in sample]\n",
    "            feature = feature[:,:,sample]\n",
    "            y_hist = y_hist[:,:,sample]\n",
    "            target = target[:,sample]\n",
    "            \n",
    "            output,att,g = model(feature.to(device), y_hist.to(device),sample,return_attention=True)\n",
    "            temp = torch.mean(att,axis=1)\n",
    "            output = output.reshape(output.shape[1],output.shape[0])\n",
    "            inferred_cg = update_graph(sample,inferred_cg,g)\n",
    "            attention = update_attention(sample,att,attention)\n",
    "            num_params = count_parameters(model)\n",
    "            #target = target.cuda()\n",
    "            loss2 = crit_mse(output,target)\n",
    "\n",
    "            n = torch.FloatTensor([feature.shape[0]])#.cuda()\n",
    "            loss = -1*(n*torch.log(loss2) + reg_factor1*get_num_cycles(inferred_cg) + reg_factor2*is_dag(inferred_cg))\n",
    "            loss_2.append(loss2)\n",
    "            loss_1.append(loss.item())\n",
    "            if(len(original_list)%1000==0):\n",
    "                print(\"The number of nodes sampled are \", 3129 - len(original_list))\n",
    "    loss_tot = 0\n",
    "    loss_21 = calc_discounted_rewards(loss_2,0.98)\n",
    "    for indexe in range(len(loss_21)):\n",
    "        loss_tot += loss_1[indexe] * torch.log(loss_21[indexe])\n",
    "    loss_tot = (loss_tot - BASELINE_REWARD) / len(loss_21)\n",
    "    loss_tot.backward()\n",
    "    optimizer.step()\n",
    "    total_loss +=loss_tot.item()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "    if(round(total_loss/(i+1),2)<=round(min_loss/(i+1),2)):\n",
    "        min_loss = total_loss\n",
    "        breakout = 0\n",
    "        torch.save(model.state_dict(),os.getcwd()+\"/Models/MyModel_GCN_FullModel_\"+str(epoch))\n",
    "    else:\n",
    "        breakout+=1\n",
    "    print(\"Loss is \", total_loss, \" for epoch \", epoch)\n",
    "    print(np.where(attention[target_index,:]!=0),len(np.where(attention[target_index,:]!=0)[0]),get_num_cycles(inferred_cg),is_dag(inferred_cg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-96.531250  30.843750\\n', '-97.531250  31.156250\\n', '-96.343750  29.843750\\n', '-97.468750  31.406250\\n', '-97.468750  30.656250\\n', '-96.218750  31.593750\\n', '-96.593750  29.968750\\n', '-97.718750  31.343750\\n', '-96.593750  30.031250\\n', '-97.468750  31.531250\\n', '-96.656250  31.156250\\n', '-96.968750  30.468750\\n', '-95.531250  29.156250\\n', '-96.406250  30.718750\\n', '-97.156250  31.406250\\n', '-95.843750  29.406250\\n', '-96.656250  31.656250\\n', '-96.281250  29.906250\\n', '-97.781250  30.968750\\n', '-97.031250  30.218750\\n', '-96.968750  31.593750\\n', '-96.593750  30.656250\\n', '-96.031250  30.593750\\n', '-97.656250  30.531250\\n', '-96.281250  30.843750\\n', '-97.468750  31.468750\\n', '-95.968750  30.093750\\n', '-96.468750  30.531250\\n', '-97.781250  31.968750\\n', '-97.593750  30.906250\\n']\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "lat": [
          30.84375,
          31.15625,
          29.84375,
          31.40625,
          30.65625,
          31.59375,
          29.96875,
          31.34375,
          30.03125,
          31.53125,
          31.15625,
          30.46875,
          29.15625,
          30.71875,
          31.40625,
          29.40625,
          31.65625,
          29.90625,
          30.96875,
          30.21875,
          31.59375,
          30.65625,
          30.59375,
          30.53125,
          30.84375,
          31.46875,
          30.09375,
          30.53125,
          31.96875,
          30.90625
         ],
         "lon": [
          -96.53125,
          -97.53125,
          -96.34375,
          -97.46875,
          -97.46875,
          -96.21875,
          -96.59375,
          -97.71875,
          -96.59375,
          -97.46875,
          -96.65625,
          -96.96875,
          -95.53125,
          -96.40625,
          -97.15625,
          -95.84375,
          -96.65625,
          -96.28125,
          -97.78125,
          -97.03125,
          -96.96875,
          -96.59375,
          -96.03125,
          -97.65625,
          -96.28125,
          -97.46875,
          -95.96875,
          -96.46875,
          -97.78125,
          -97.59375
         ],
         "marker": {
          "color": "red",
          "size": 10
         },
         "mode": "markers",
         "type": "scattermapbox"
        }
       ],
       "layout": {
        "height": 900,
        "mapbox": {
         "center": {
          "lat": 36.5,
          "lon": 139
         },
         "style": "stamen-terrain",
         "zoom": 4.5
        },
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1600
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "at1 = frame.columns[attention[target_index,:].argsort()[-100:]]\n",
    "c=0\n",
    "at2=[]\n",
    "for i in at1:\n",
    "    if(float(i.split()[1])<32):\n",
    "        at2.append(i)\n",
    "        c+=1\n",
    "    if(c==30):\n",
    "        break\n",
    "print(at2)\n",
    "plot_graph(at2,\"mapTestFT1.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "lat": [
          28.85,
          31.96875,
          31.96875,
          31.96875,
          31.96875,
          31.96875,
          31.96875,
          31.96875,
          31.96875,
          31.96875,
          31.96875,
          31.96875,
          31.96875,
          31.96875,
          31.96875,
          31.96875,
          31.90625,
          31.90625,
          31.90625,
          31.90625,
          31.90625,
          31.90625,
          31.90625,
          31.90625,
          31.90625,
          31.90625,
          31.90625,
          31.90625,
          31.90625,
          31.90625
         ],
         "lon": [
          -95.35,
          -98.90625,
          -98.84375,
          -98.71875,
          -98.65625,
          -98.59375,
          -98.46875,
          -98.34375,
          -98.21875,
          -97.78125,
          -97.59375,
          -97.53125,
          -97.46875,
          -97.40625,
          -97.28125,
          -97.21875,
          -98.84375,
          -98.78125,
          -98.71875,
          -98.65625,
          -98.53125,
          -98.46875,
          -98.28125,
          -98.15625,
          -98.09375,
          -98.03125,
          -97.96875,
          -97.84375,
          -97.78125,
          -97.65625
         ],
         "marker": {
          "color": "red",
          "size": 10
         },
         "mode": "markers",
         "type": "scattermapbox"
        }
       ],
       "layout": {
        "height": 900,
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1600
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "te12 = frame.columns[[0, 4, 6, 7, 9, 11, 12, 13, 16, 17, 19, 22, 24, 26, 28, 29, 32, 33, 34, 47, 51, 52, 53, 54, 56, 58, 60, 61, 63, 64, 65, 66, 69, 71, 72, 76, 80, 81, 83, 85, 88, 89, 90, 94, 95, 96, 97, 98, 99, 103, 104, 107, 108, 109, 114, 117, 118, 126, 127, 129, 132, 134, 137, 138, 140, 141, 144, 146, 149, 150, 153, 156, 157, 158, 162, 163, 169, 170, 172, 175, 176, 181, 182, 184, 185, 186, 187, 189, 191, 193, 198, 199, 201, 202, 209, 210, 211, 212, 214, 216, 217, 218, 224, 232, 233, 235, 236, 239, 240, 241, 242, 244, 245, 246, 248, 250, 251, 253, 255, 259, 260, 261, 263, 266, 267, 268, 269, 271, 272, 275, 276, 278, 279, 281, 283, 285, 287, 288, 289, 292, 295, 297, 298, 302, 303, 304, 305, 306, 307, 308, 311, 312, 314, 315, 320, 321, 325, 326, 328, 331, 332, 333, 334, 335, 336, 339, 340, 343, 344, 345, 349, 352, 353, 358, 359, 360, 366, 375, 379, 380, 383, 384, 387, 389, 393, 395, 396, 399, 401, 403, 405, 406, 407, 410, 411, 413, 414, 416, 417, 420, 422, 425, 427, 430, 431, 433, 434, 436, 438, 440, 449, 450, 452, 457, 459, 460, 461, 462, 464, 465, 468, 469, 471, 472, 473, 474, 479, 480, 482, 483, 486, 488, 489, 492, 494, 496, 499, 500, 502, 504, 508, 509, 511, 515, 517, 518, 521, 523, 524, 526, 527, 529, 530, 532, 536, 539, 543, 558, 559, 563, 564, 569, 571, 573, 575, 576, 584, 585, 591, 592, 595, 598, 600, 608, 609, 614, 615, 619, 622, 626, 628, 630, 631, 634, 637, 638, 640, 641, 642, 643, 644, 645, 646, 647, 650, 652, 654, 655, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 672, 673, 676, 680, 685, 686, 688, 691, 696, 697, 701, 705, 706, 708, 712, 713, 718, 723, 728, 730, 732, 733, 734, 736, 738, 743, 744, 745, 747, 749, 750, 752, 753, 754, 755, 756, 759, 761, 762, 763, 765, 766, 767, 768, 769, 770, 771, 772, 773, 777, 779, 783, 786, 787, 793, 795, 796, 797, 798, 800, 803, 805, 806, 807, 809, 811, 814, 816, 818, 820, 821, 822, 823, 824, 825, 826, 832, 833, 835, 836, 838, 840, 841, 843, 844, 846, 849, 850, 853, 857, 858, 861, 864, 867, 868, 870, 874, 875, 877, 878, 882, 884, 888, 889, 891, 893, 895, 896, 897, 898, 899, 900, 901, 902, 905, 910, 913, 915, 917, 919, 921, 923, 925, 928, 930, 932, 933, 939, 944, 945, 946, 952, 953, 954, 955, 956, 958, 964, 965, 966, 967, 968, 969, 970, 972, 978, 980, 981, 984, 989, 992, 993, 1003, 1004, 1006, 1009, 1010, 1011, 1016, 1018, 1021, 1022, 1025, 1027, 1028, 1033, 1034, 1037, 1041, 1043, 1045, 1046, 1047, 1049, 1052, 1055, 1057, 1058, 1059, 1062, 1063, 1066, 1067, 1069, 1071, 1075, 1078, 1079, 1081, 1082, 1083, 1085, 1087, 1088, 1090, 1094, 1096, 1097, 1098, 1099, 1103, 1104, 1105, 1106, 1107, 1114, 1115, 1119, 1120, 1124, 1125, 1126, 1127, 1128, 1130, 1131, 1132, 1133, 1143, 1144, 1145, 1146, 1148, 1150, 1151, 1153, 1154, 1157, 1158, 1161, 1163, 1164, 1165, 1170, 1171, 1177, 1179, 1183, 1185, 1188, 1191, 1193, 1194, 1195, 1197, 1201, 1202, 1204, 1207, 1208, 1213, 1214, 1215, 1226, 1227, 1230, 1232, 1233, 1234, 1236, 1237, 1239, 1241, 1247, 1248, 1252, 1254, 1255, 1256, 1257, 1258, 1259, 1262, 1266, 1268, 1270, 1274, 1275, 1277, 1278, 1283, 1286, 1288, 1290, 1291, 1295, 1296, 1298, 1299, 1300, 1303, 1306, 1307, 1310, 1311, 1312, 1316, 1320, 1323, 1324, 1328, 1329, 1332, 1334, 1335, 1336, 1339, 1340, 1341, 1344, 1351, 1352, 1354, 1356, 1358, 1361, 1362, 1365, 1367, 1368, 1369, 1372, 1373, 1378, 1380, 1383, 1384, 1386, 1388, 1394, 1395, 1397, 1398, 1402, 1403, 1404, 1406, 1414, 1417, 1419, 1420, 1421, 1424, 1425, 1428, 1430, 1433, 1434, 1437, 1438, 1439, 1442, 1444, 1445, 1449, 1451, 1453, 1459, 1465, 1473, 1475, 1479, 1481, 1482, 1483, 1486, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1497, 1499, 1500, 1501, 1503, 1504, 1505, 1506, 1510, 1513, 1514, 1519, 1520, 1526, 1529, 1532, 1534, 1538, 1539, 1540, 1542, 1544, 1545, 1546, 1547, 1548, 1550, 1552, 1559, 1562, 1563, 1564, 1565, 1568, 1570, 1571, 1574, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1584, 1586, 1588, 1589, 1594, 1595, 1596, 1599, 1600, 1601, 1608, 1609, 1612, 1613, 1614, 1615, 1616, 1617, 1619, 1620, 1621, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1645, 1646, 1650, 1651, 1652, 1653, 1658, 1660, 1662, 1664, 1665, 1671, 1674, 1675, 1676, 1678, 1679, 1680, 1684, 1688, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1702, 1703, 1704, 1706, 1707, 1709, 1710, 1714, 1715, 1718, 1720, 1721, 1722, 1724, 1725, 1727, 1729, 1731, 1734, 1735, 1738, 1739, 1740, 1741, 1742, 1743, 1745, 1748, 1749, 1750, 1752, 1754, 1756, 1758, 1759, 1760, 1762, 1763, 1765, 1767, 1769, 1771, 1774, 1775, 1779, 1780, 1783, 1784, 1786, 1788, 1791, 1793, 1794, 1796, 1800, 1801, 1802, 1804, 1807, 1808, 1809, 1810, 1812, 1817, 1818, 1819, 1820, 1821, 1822, 1826, 1827, 1830, 1832, 1835, 1837, 1838, 1841, 1844, 1845, 1847, 1849, 1851, 1852, 1854, 1855, 1857, 1860, 1862, 1865, 1866, 1867, 1869, 1870, 1875, 1876, 1877, 1879, 1882, 1885, 1887, 1892, 1893, 1895, 1897, 1898, 1899, 1901, 1902, 1903, 1905, 1907, 1908, 1909, 1912, 1913, 1914, 1917, 1921, 1926, 1937, 1938, 1939, 1941, 1945, 1949, 1950, 1951, 1953, 1957, 1958, 1959, 1961, 1963, 1964, 1965, 1969, 1971, 1975, 1976, 1977, 1978, 1979, 1984, 1985, 1986, 1987, 1989, 1990, 1991, 1993, 1995, 1997, 2004, 2007, 2008, 2009, 2010, 2012, 2013, 2017, 2018, 2019, 2020, 2022, 2023, 2026, 2028, 2029, 2030, 2031, 2033, 2034, 2036, 2037, 2038, 2040, 2043, 2046, 2049, 2050, 2056, 2057, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2072, 2073, 2083, 2086, 2091, 2092, 2096, 2099, 2100, 2101, 2103, 2104, 2107, 2108, 2111, 2112, 2116, 2117, 2118, 2119, 2120, 2121, 2126, 2127, 2130, 2131, 2132, 2133, 2140, 2141, 2142, 2145, 2146, 2149, 2150, 2153, 2154, 2155, 2157, 2161, 2162, 2163, 2165, 2166, 2169, 2170, 2172, 2174, 2175, 2177, 2179, 2185, 2187, 2190, 2192, 2194, 2195, 2196, 2197, 2198, 2200, 2201, 2205, 2206, 2212, 2215, 2217, 2220, 2222, 2224, 2226, 2230, 2232, 2233, 2235, 2236, 2237, 2239, 2241, 2242, 2243, 2244, 2249, 2251, 2252, 2253, 2256, 2258, 2259, 2260, 2262, 2263, 2264, 2265, 2270, 2275, 2280, 2283, 2284, 2286, 2289, 2292, 2293, 2294, 2295, 2296, 2302, 2303, 2305, 2307, 2309, 2313, 2316, 2317, 2318, 2321, 2323, 2326, 2327, 2328, 2331, 2336, 2338, 2339, 2341, 2342, 2344, 2349, 2350, 2351, 2352, 2354, 2359, 2363, 2365, 2369, 2371, 2375, 2376, 2378, 2381, 2384, 2388, 2392, 2396, 2398, 2401, 2402, 2403, 2405, 2406, 2407, 2408, 2411, 2412, 2414, 2415, 2417, 2418, 2420, 2422, 2425, 2429, 2430, 2438, 2439, 2440, 2444, 2446, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2463, 2465, 2466, 2473, 2474, 2475, 2476, 2479, 2480, 2481, 2484, 2487, 2488, 2489, 2494, 2497, 2499, 2500, 2501, 2502, 2504, 2505, 2508, 2510, 2512, 2514, 2518, 2519, 2521, 2526, 2530, 2532, 2537, 2539, 2541, 2547, 2548, 2550, 2551, 2552, 2554, 2556, 2557, 2558, 2562, 2564, 2566, 2569, 2570, 2576, 2578, 2580, 2583, 2586, 2587, 2592, 2593, 2594, 2595, 2596, 2601, 2609, 2610, 2612, 2614, 2616, 2617, 2623, 2625, 2629, 2632, 2634, 2636, 2637, 2642, 2646, 2647, 2648, 2652, 2654, 2658, 2659, 2660, 2661, 2662, 2663, 2664, 2665, 2666, 2667, 2668, 2670, 2672, 2673, 2676, 2678, 2679, 2682, 2686, 2687, 2688, 2689, 2690, 2695, 2697, 2698, 2699, 2700, 2703, 2708, 2711, 2713, 2715, 2720, 2721, 2722, 2726, 2728, 2729, 2730, 2731, 2733, 2734, 2738, 2740, 2746, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755, 2760, 2767, 2771, 2773, 2777, 2778, 2782, 2784, 2785, 2787, 2789, 2791, 2796, 2797, 2798, 2799, 2800, 2802, 2807, 2810, 2811, 2812, 2814, 2815, 2817, 2818, 2819, 2820, 2821, 2823, 2824, 2829, 2832, 2833, 2834, 2835, 2836, 2839, 2840, 2841, 2843, 2848, 2851, 2857, 2858, 2859, 2860, 2865, 2866, 2867, 2868, 2870, 2871, 2872, 2880, 2881, 2885, 2886, 2887, 2895, 2898, 2901, 2905, 2907, 2908, 2910, 2911, 2913, 2915, 2918, 2920, 2921, 2922, 2927, 2929, 2932, 2933, 2936, 2938, 2939, 2943, 2944, 2947, 2948, 2950, 2953, 2960, 2961, 2962, 2963, 2967, 2972, 2974, 2978, 2979, 2980, 2981, 2982, 2983, 2986, 2989, 2990, 2994, 2997, 2998, 3000, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3015, 3016, 3018, 3019, 3021, 3022, 3024, 3026, 3027, 3028, 3030, 3031, 3032, 3041, 3044, 3045, 3048, 3052, 3054, 3055, 3057, 3062, 3063, 3065, 3067, 3073, 3074, 3082, 3083, 3084, 3085, 3090, 3092, 3095, 3098, 3104, 3107, 3111, 3112, 3114, 3116, 3120, 3121]]\n",
    "te213 = []\n",
    "c=0\n",
    "for i in te12:\n",
    "    if(float(i.split()[1])<32):\n",
    "        te213.append(i)\n",
    "        c+=1\n",
    "    if(c==30):\n",
    "        break\n",
    "print(len(te213))\n",
    "plot_graph(te213, \"mapTestFT1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = list(np.where(attention[target_index,:]>np.mean(attention[target_index,:]))[0])\n",
    "cols = list(frame.columns[index_list])\n",
    "with open(\"index_list.txt\", \"w\") as output:\n",
    "    output.write(str(index_list))\n",
    "with open(\"cols.txt\", \"w\") as output:\n",
    "    output.write(str(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(a_new,fname):\n",
    "    latitude = []\n",
    "    longitude = []\n",
    "    for j,i in enumerate(a_new):\n",
    "            latitude.append(float(i.split()[0]))\n",
    "            longitude.append(float(i.split()[1]))\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scattermapbox(\n",
    "        mode = \"markers\",\n",
    "        lat = longitude,\n",
    "        lon = latitude,\n",
    "        marker = { 'color':'red',\n",
    "                    'size': 10}\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(margin={'l':0,'t':0,'b':0,'r':0},\n",
    "                    mapbox={\n",
    "                        'center':{'lon':139,'lat':36.5},\n",
    "                        'style': \"stamen-terrain\",\n",
    "                        'zoom' : 4.5},\n",
    "                    width=1600,\n",
    "                    height=900,)\n",
    "    fig.show()\n",
    "    fig.write_html(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "x = attention[target_index,:].argsort()[-30:][::-1]\n",
    "test['locations'] = frame.columns[x]\n",
    "test['attention'] = attention[target_index,x]\n",
    "test['longitude'] = test['locations'].apply(lambda x: float(x.split()[0]))\n",
    "test['latitude'] = test['locations'].apply(lambda x: float(x.split()[1]))\n",
    "test['attention'][0] = max(test['attention'][1:])\n",
    "test = test.loc[:,['longitude','latitude','attention']]\n",
    "# test['attention'] = (test['attention'] - test['attention'].min()) / (test['attention'].max() - test['attention'].min())\n",
    "test['attention'] = test['attention']/test['attention'].sum()\n",
    "# test.loc[len(test.index)] = [-97.843750, 32.531250, 0.6] \n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.density_mapbox(test, lat='latitude', lon='longitude', z='attention', radius=10,\n",
    "                        center=dict(lat=0, lon=180), zoom=0,\n",
    "                        color_continuous_scale=[[0.0, 'rgb(255, 0, 0)'],[0.2, 'rgb(255, 0, 0)'],[0.4, 'rgb(255, 255, 0)'],[0.6, 'rgb(0, 255, 0)'],[0.8, 'rgb(0, 255, 255)'],[1.0, 'rgb(0, 0, 255)']],\n",
    "                        mapbox_style=\"stamen-terrain\")\n",
    "fig.show()\n",
    "fig.write_html(\"mapTestWS1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.columns[target_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = attention[target_index,:].argsort()[-30:][::-1]\n",
    "# y = inferred_cg[:,1200].argsort()[-30:][::-1]\n",
    "# plot_graph(frame.columns[y],\"GCNgraph_inf1.html\")\n",
    "plot_graph(frame.columns[x],\"GCNgraph_att1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.columns[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = attention[:,1200]\n",
    "inds = np.where(t>np.mean(t))[0]\n",
    "sorted_indexes = inds[np.argsort(t[inds])[::-1]]\n",
    "sorted_indexes[0:30]\n",
    "plot_graph(frame.columns[sorted_indexes[0:30]],\"GCNgraph_inf2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create an example array\n",
    "arr = inferred_cg[:,1200]\n",
    "\n",
    "# initialize an empty list to store the indexes of the top 30 unique values\n",
    "top_indexes = []\n",
    "\n",
    "# iterate over the array and find the indexes of the top 30 unique values\n",
    "for i in range(30):\n",
    "    # find the index of the maximum value that hasn't already been added to the list\n",
    "    max_index = np.argmax(arr)\n",
    "    while max_index in top_indexes:\n",
    "        arr[max_index] = -np.inf  # set the maximum value to -inf so it won't be selected again\n",
    "        max_index = np.argmax(arr)\n",
    "    \n",
    "    # add the current index to the top_indexes list\n",
    "    top_indexes.append(max_index)\n",
    "\n",
    "candidates = frame.columns[top_indexes]\n",
    "target = frame.columns[1200]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import distance\n",
    "\n",
    "# example list of latitude longitude coordinates\n",
    "coords_str = frame.columns[x]\n",
    "\n",
    "# target latitude longitude\n",
    "target_lat = float(target.split()[1])\n",
    "target_lon = float(target.split()[0])\n",
    "\n",
    "# convert coordinates to float values and calculate distances from target\n",
    "coords = [tuple(map(float, c.split()[::-1])) for c in coords_str]\n",
    "distances = [distance((target_lat, target_lon), c).km for c in coords]\n",
    "\n",
    "# determine which points are above and below the target and output index and 1 or -1\n",
    "for i, d in enumerate(distances):\n",
    "    if coords[i][0] >= target_lat:\n",
    "        print(f\"Point {i}: 1\")\n",
    "    else:\n",
    "        print(f\"Point {i}: -1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"C:/Users/psheth5/STCD-RL/data/data/StandardizedData.csv\").columns[3000:3129]\n",
    "x = pd.DataFrame()\n",
    "x['longitude'] = data.str.split().str[0]\n",
    "x['latitude'] = data.str.split().str[1]\n",
    "x['longitude'] = x['longitude'].astype(float)\n",
    "x['latitude'] = x['latitude'].astype(float)\n",
    "\n",
    "x.to_csv(\"lonlatinfo7.txt\",index=False,header=False,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevate = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"C:/Users/psheth5/STCD-RL/data/data/bulk-pqs (6).csv\",header=None)\n",
    "elevate = pd.concat([elevate,x],axis=0)\n",
    "print(elevate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows to be dropped\n",
    "rows_to_drop = [501, 1002, 1503, 2004, 2505, 3006]\n",
    "\n",
    "# Drop specific rows\n",
    "elevate = elevate.drop(elevate.index[rows_to_drop])\n",
    "\n",
    "# Reset the index if needed\n",
    "elevate = elevate.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check the modified dataframe\n",
    "elevations = elevate[3].values\n",
    "\n",
    "# Create an empty adjacency matrix\n",
    "adjacency_matrix = np.zeros((len(elevations), len(elevations)))\n",
    "\n",
    "# Populate the adjacency matrix based on the condition\n",
    "for i in range(len(elevations)):\n",
    "    for j in range(len(elevations)):\n",
    "        if elevations[i] > elevations[j]:\n",
    "            adjacency_matrix[i, j] = 1\n",
    "\n",
    "# Check the adjacency matrix\n",
    "print(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"ElevationAdjacency.npy\",adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a6511c335c26d02572349af57853ebfcc20500c776be641a45dee87cf591594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
