{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from itertools import combinations,permutations\n",
    "\n",
    "torch.manual_seed(99)\n",
    "np.random.seed(99)\n",
    "torch.cuda.empty_cache()\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as tf\n",
    "\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import torch\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "import plotly.graph_objects as go\n",
    "from scipy.sparse import coo_matrix\n",
    "from geopy.distance import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = pd.read_csv(\"C:/Users/psheth5/STCD-RL/data/data/watershed_avg.csv\")\n",
    "frame = pd.read_csv(\"C:/Users/psheth5/STCD-RL/data/data/StandardizedData.csv\")\n",
    "n_features = frame.shape[1]\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# adj_mat = np.load('C:/Users/psheth5/STCD-RL/data/data/watershed.npy')\n",
    "\n",
    "adj_mat = np.load('ElevationAdjacency.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # distances = np.load('C:/Users/psheth5/STCD-RL/distance.npy')\n",
    "# # np.fill_diagonal(distance, np.inf)\n",
    "# # distances[np.isfinite(distance)] = 1   # replace finite values with 1\n",
    "# # distances[~np.isfinite(distance)] = 0   # replace infinite values with 0\n",
    "# # distances\n",
    "\n",
    "# list_of_coords_str = frame.columns # your list of 3129 latitude longitude values\n",
    "# list_of_coords = [tuple(map(float, c.split()[::-1])) for c in list_of_coords_str]\n",
    "# adj_matrix_list = np.zeros((len(list_of_coords), len(frame.columns)))\n",
    "# for i, c1 in enumerate(list_of_coords):\n",
    "#     for j, c2 in enumerate(list_of_coords):\n",
    "#         if c2[0] > c1[0] and distance(c1, c2).km > 0:\n",
    "#             adj_matrix_list[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adj_mat = np.load('C:/Users/psheth5/STCD-RL/data/data/watershed.npy')\n",
    "# coo = coo_matrix(adj_matrix_list, dtype = \"int8\")\n",
    "coo = coo_matrix(adj_mat, dtype = \"int8\")\n",
    "row = torch.from_numpy(coo.row.astype(np.int64)).to(torch.long)\n",
    "col = torch.from_numpy(coo.col.astype(np.int64)).to(torch.long)\n",
    "edge_index = torch.stack([row, col], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"data\\\\data\\\\adj_mat_new.npy\", adj_matrix_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def filter_edge_index(edge_index, coords):\n",
    "    filtered_index = []\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        u = edge_index[0][i]\n",
    "        v = edge_index[1][i]\n",
    "        # check if u is above v\n",
    "        if torch.tensor(coords[u][0]) > torch.tensor(coords[v][0]) and u != v:\n",
    "            filtered_index.append([u, v])\n",
    "    filtered_index = np.array(filtered_index).T\n",
    "    return filtered_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index = filter_edge_index(edge_index, list_of_coords)\n",
    "# edge_index = torch.from_numpy(edge_index.astype(np.int64)).to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping function\n",
    "def map_values(value, value_range):\n",
    "    \"\"\"Maps a value from the input range to the output range.\"\"\"\n",
    "    input_min, input_max = value_range\n",
    "    output_min, output_max = (0, 99)\n",
    "    return torch.floor(((value - input_min) / (input_max - input_min)) * (output_max - output_min) + output_min).long()\n",
    "\n",
    "\n",
    "def reverse_map_values(mapped_value, value_range):\n",
    "    \"\"\"Maps a value from the output range to the input range.\"\"\"\n",
    "    input_min, input_max = value_range\n",
    "    output_min, output_max = (0, 99)\n",
    "    return torch.floor(((mapped_value - output_min) / (output_max - output_min)) * (input_max - input_min) + input_min).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tasks(Enum):\n",
    "    prediction = \"prediction\"\n",
    "    reconstruction = \"reconstruction\"\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(object):\n",
    "    def __init__(self, task: Tasks, data_path: str, categorical_cols: List[str], index_col: str, target_col: str,\n",
    "                 seq_length: int, batch_size: int, prediction_window: int = 1):\n",
    "        \"\"\"\n",
    "        :param task: name of the task\n",
    "        :param data_path: path to datafile\n",
    "        :param categorical_cols: name of the categorical columns, if None pass empty list\n",
    "        :param index_col: column to use as index\n",
    "        :param target_col: name of the targeted column\n",
    "        :param seq_length: window length to use\n",
    "        :param batch_size:\n",
    "        :param prediction_window: window length to predict\n",
    "        \"\"\"\n",
    "        self.task = task.value\n",
    "\n",
    "        \n",
    "\n",
    "        # data_path = pkg_resources.resource_filename(\"tsa\", data_path)\n",
    "        self.data = pd.read_csv(data_path, index_col=index_col)[0:1460]\n",
    "        # a  = [self.data.columns[0]]\n",
    "        # a.extend(self.data.columns[-250:])\n",
    "        # self.data = self.data[a]\n",
    "        self.categorical_cols = categorical_cols\n",
    "        # self.numerical_cols = list(set(self.data.columns) - set(categorical_cols) - set(target_col))\n",
    "        self.numerical_cols = self.data.columns\n",
    "        print(len(self.numerical_cols))\n",
    "        self.target_col = target_col\n",
    "\n",
    "        self.seq_length = seq_length\n",
    "        self.prediction_window = prediction_window\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        transformations = [(\"scaler\", StandardScaler(), self.numerical_cols)]\n",
    "        if len(self.categorical_cols) > 0:\n",
    "            transformations.append((\"encoder\", OneHotEncoder(), self.categorical_cols))\n",
    "        self.preprocessor = ColumnTransformer(transformations, remainder=\"passthrough\")\n",
    "\n",
    "        if self.task == \"prediction\":\n",
    "            self.y_scaler = StandardScaler()\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Preprocessing function\"\"\"\n",
    "        X = self.data#.drop(self.target_col, axis=1,inplace=False)\n",
    "        # y = self.data[self.target_col]\n",
    "\n",
    "        X_train, X_test = train_test_split(X,train_size=0.8, shuffle=False)\n",
    "        X_train = self.preprocessor.fit_transform(X_train)\n",
    "        X_test = self.preprocessor.transform(X_test)\n",
    "\n",
    "        # if self.task == \"prediction\":\n",
    "        #     y_train = self.y_scaler.fit_transform([y_train])\n",
    "        #     y_test = self.y_scaler.fit_transform([y_test])\n",
    "        #     return X_train, X_test, y_train.reshape(-1,1), y_test.reshape(-1,1)\n",
    "        return X_train, X_test, None,None\n",
    "\n",
    "    def frame_series(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Function used to prepare the data for time series prediction\n",
    "        :param X: set of features\n",
    "        :param y: targeted value to predict\n",
    "        :return: TensorDataset\n",
    "        \"\"\"\n",
    "        nb_obs, nb_features = X.shape\n",
    "        features, target, y_hist = [], [], []\n",
    "\n",
    "        for i in range(1, nb_obs - self.seq_length - self.prediction_window):\n",
    "            features.append(torch.FloatTensor(X[i:i + self.seq_length, :]).unsqueeze(0))\n",
    "\n",
    "            if self.task == \"prediction\":\n",
    "                # lagged output used for prediction\n",
    "                y_hist.append(torch.FloatTensor(y[i - 1:i + self.seq_length - 1]).unsqueeze(0))\n",
    "                # shifted target\n",
    "                target.append(torch.FloatTensor(y[i + self.seq_length:i + self.seq_length + self.prediction_window]).unsqueeze(0))\n",
    "            else:\n",
    "                y_hist.append(torch.FloatTensor(X[i - 1: i + self.seq_length - 1, :]).unsqueeze(0))\n",
    "                target.append(\n",
    "                    torch.FloatTensor(X[i + self.seq_length:i + self.seq_length + self.prediction_window, :]))\n",
    "\n",
    "        features_var = torch.cat(features)\n",
    "        y_hist_var = torch.cat(y_hist)\n",
    "        target_var = torch.cat(target)\n",
    "\n",
    "        return TensorDataset(features_var, y_hist_var, target_var)\n",
    "\n",
    "    def get_loaders(self):\n",
    "        \"\"\"\n",
    "        Preprocess and frame the dataset\n",
    "\n",
    "        :return: DataLoaders associated to training and testing data\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = self.preprocess_data()\n",
    "        nb_features = X_train.shape[1]\n",
    "\n",
    "        train_dataset = self.frame_series(X_train, y_train)\n",
    "        test_dataset = self.frame_series(X_test, y_test)\n",
    "\n",
    "        train_iter = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "        test_iter = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "        return train_iter, test_iter, nb_features\n",
    "\n",
    "    def invert_scale(self, predictions):\n",
    "        \"\"\"\n",
    "        Inverts the scale of the predictions\n",
    "        \"\"\"\n",
    "        if isinstance(predictions, torch.Tensor):\n",
    "            predictions = predictions.numpy()\n",
    "\n",
    "        if predictions.ndim == 1:\n",
    "            predictions = predictions.reshape(-1, 1)\n",
    "\n",
    "        if self.task == \"prediction\":\n",
    "            unscaled = self.y_scaler.inverse_transform(predictions)\n",
    "        else:\n",
    "            unscaled = self.preprocessor.named_transformers_[\"scaler\"].inverse_transform(predictions)\n",
    "        return torch.Tensor(unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Tasks('reconstruction')\n",
    "data1 = TimeSeriesDataset(task=task,data_path=\"C:/Users/psheth5/STCD-RL/data/data/StandardizedData.csv\",categorical_cols=[],index_col=None,target_col=frame.columns[0],seq_length=30,batch_size=256,prediction_window=1)\n",
    "train_iter, test_iter, nb_features = data1.get_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "def init_hidden(x: torch.Tensor, hidden_size: int, num_dir: int = 1, xavier: bool = True):\n",
    "    \"\"\"\n",
    "    Initialize hidden.\n",
    "\n",
    "    Args:\n",
    "        x: (torch.Tensor): input tensor\n",
    "        hidden_size: (int):\n",
    "        num_dir: (int): number of directions in LSTM\n",
    "        xavier: (bool): wether or not use xavier initialization\n",
    "    \"\"\"\n",
    "    if xavier:\n",
    "        return nn.init.xavier_normal_(torch.zeros(num_dir, x.size(0), hidden_size)).to(device)\n",
    "    return Variable(torch.zeros(num_dir, x.size(0), hidden_size)).to(device)\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "################################ ENCODERS #################################\n",
    "###########################################################################\n",
    "class AttnEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size_encoder,seq_len,denoising,directions,input_size,edge_index,spatial,use_spatial=False):\n",
    "        \"\"\"\n",
    "        Initialize the network.\n",
    "\n",
    "        Args:\n",
    "            config:\n",
    "            input_size: (int): size of the input\n",
    "        \"\"\"\n",
    "        super(AttnEncoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size_encoder\n",
    "        self.seq_len = seq_len\n",
    "        self.add_noise = denoising\n",
    "        self.gcn_e = GCNConv(in_channels=-1, out_channels=self.hidden_size)\n",
    "        self.directions = directions\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=1\n",
    "        )\n",
    "        self.attn = nn.Linear(\n",
    "            in_features=2 * self.hidden_size + self.seq_len,\n",
    "            out_features=1\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.edge_index=edge_index\n",
    "        self.use_spatial = use_spatial\n",
    "        self.spatial_mat = spatial\n",
    "\n",
    "    def forward(self, input_data: torch.Tensor,sample:torch.Tensor):\n",
    "        \"\"\"\n",
    "        Forward computation.\n",
    "\n",
    "        Args:\n",
    "            input_data: (torch.Tensor): tensor of input data\n",
    "        \"\"\"\n",
    "        spatial = self.spatial_mat[sample]\n",
    "        spatial = spatial.to(device)\n",
    "        h_t, c_t = (init_hidden(input_data, self.hidden_size, num_dir=self.directions),\n",
    "                    init_hidden(input_data, self.hidden_size, num_dir=self.directions))\n",
    "\n",
    "        # apply the mapping function to the sampled tensor\n",
    "        a = self.edge_index[0][sample]\n",
    "        b = self.edge_index[1][sample]\n",
    "        sample_edge_index = torch.stack([a, b], dim=0)\n",
    "        mapped_arr = map_values(sample_edge_index, (sample_edge_index.min(), sample_edge_index.max()))\n",
    "        \n",
    "        attentions, input_encoded = (Variable(torch.zeros(input_data.size(0), self.seq_len, self.input_size)),\n",
    "                                     Variable(torch.zeros(input_data.size(0), self.seq_len, self.hidden_size)))\n",
    "\n",
    "        if self.add_noise and self.training:\n",
    "            input_data += self._get_noise(input_data).to(device)\n",
    "        \n",
    "        for t in range(self.seq_len):\n",
    "            x = torch.cat((h_t.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
    "                           c_t.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
    "                           input_data.permute(0, 2, 1).to(device)), dim=2).to(\n",
    "                device)  # bs * input_size * (2 * hidden_dim + seq_len)\n",
    "\n",
    "            e_t = self.attn(x.view(-1, self.hidden_size * 2 + self.seq_len))  # (bs * input_size) * 1\n",
    "            a_t = self.softmax(e_t.view(-1, self.input_size)).to(device)  # (bs, input_size)\n",
    "            weighted_input = torch.mul(a_t, input_data[:, t, :].to(device))  # (bs * input_size)\n",
    "            self.lstm.flatten_parameters()\n",
    "            _, (h_t, c_t) = self.lstm(weighted_input.unsqueeze(0), (h_t, c_t))\n",
    "\n",
    "            if(self.use_spatial):\n",
    "                h_t = self.gcn_e(h_t,mapped_arr.to(device))\n",
    "            input_encoded[:, t, :] = h_t\n",
    "            attentions[:, t, :] = a_t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return attentions, input_encoded\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "################################ DECODERS #################################\n",
    "###########################################################################\n",
    "\n",
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, seq_len,hidden_size_encoder,hidden_size_decoder,output_size,edge_index):\n",
    "        \"\"\"\n",
    "        Initialize the network.\n",
    "\n",
    "        Args:\n",
    "            config:\n",
    "        \"\"\"\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.encoder_hidden_size = hidden_size_encoder\n",
    "        self.decoder_hidden_size = hidden_size_decoder\n",
    "        self.out_feats = output_size\n",
    "\n",
    "        self.gcn_d = GCNConv(in_channels=-1, out_channels=self.decoder_hidden_size)\n",
    "\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(2 * self.decoder_hidden_size + self.encoder_hidden_size, self.encoder_hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.encoder_hidden_size, 1)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(input_size=self.out_feats, hidden_size=self.decoder_hidden_size)\n",
    "        self.fc = nn.Linear(self.encoder_hidden_size + self.out_feats, self.out_feats)\n",
    "        self.fc_out = nn.Linear(self.decoder_hidden_size + self.encoder_hidden_size, self.out_feats)\n",
    "        self.fc.weight.data.normal_()\n",
    "        self.edge_index = edge_index\n",
    "    \n",
    "\n",
    "    def forward(self, input_encoded: torch.Tensor, y_history: torch.Tensor, sample: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Perform forward computation.\n",
    "\n",
    "        Args:\n",
    "            input_encoded: (torch.Tensor): tensor of encoded input\n",
    "            y_history: (torch.Tensor): shifted target\n",
    "        \"\"\"\n",
    "        h_t, c_t = (init_hidden(input_encoded, self.decoder_hidden_size), init_hidden(input_encoded, self.decoder_hidden_size))\n",
    "        context = Variable(torch.zeros(input_encoded.size(0), self.encoder_hidden_size))\n",
    "\n",
    "        a = self.edge_index[0][sample]\n",
    "        b = self.edge_index[1][sample]\n",
    "        sample_edge_index = torch.stack([a, b], dim=0)\n",
    "        mapped_arr = map_values(sample_edge_index, (sample_edge_index.min(), sample_edge_index.max()))\n",
    "\n",
    "        for t in range(self.seq_len):\n",
    "            x = torch.cat((h_t.repeat(self.seq_len, 1, 1).permute(1, 0, 2),\n",
    "                           c_t.repeat(self.seq_len, 1, 1).permute(1, 0, 2),\n",
    "                           input_encoded.to(device)), dim=2)\n",
    "            x = tf.softmax(\n",
    "                self.attn(\n",
    "                    x.view(-1, 2 * self.decoder_hidden_size + self.encoder_hidden_size)\n",
    "                ).view(-1, self.seq_len),\n",
    "                dim=1)\n",
    "            context = torch.bmm(x.unsqueeze(1), input_encoded.to(device))[:, 0, :]  # (batch_size, encoder_hidden_size)\n",
    "            y_tilde = self.fc(torch.cat((context.to(device), y_history[:, t].to(device)),\n",
    "                                        dim=1))  # (batch_size, out_size)            \n",
    "            self.lstm.flatten_parameters()\n",
    "            _, (h_t, c_t) = self.lstm(y_tilde.unsqueeze(0), (h_t, c_t))\n",
    "            h_t = self.gcn_d(h_t,mapped_arr.to(device))\n",
    "        \n",
    "\n",
    "        return self.fc_out(torch.cat((h_t[0], context.to(device)), dim=1))  # predicting value at t=self.seq_length+1\n",
    "\n",
    "\n",
    "class AutoEncForecast(nn.Module):\n",
    "    def __init__(self, input_att,temporal_att,hidden_size_encoder,seq_len,denoising,directions,hidden_size_decoder,input_size,output_size,sample_size,edge_index,spatial_matrix,use_spatial=False):\n",
    "        \"\"\"\n",
    "        Initialize the network.\n",
    "\n",
    "        Args:\n",
    "            config:\n",
    "            input_size: (int): size of the input\n",
    "        \"\"\"\n",
    "        super(AutoEncForecast, self).__init__()\n",
    "        self.encoder = AttnEncoder(hidden_size_encoder,seq_len,denoising,directions,input_size,edge_index,spatial_matrix,use_spatial).to(device) if input_att else \\\n",
    "            Encoder(hidden_size_encoder, seq_len, input_size,edge_index).to(device)\n",
    "        self.decoder = AttnDecoder(seq_len,hidden_size_encoder,hidden_size_decoder,output_size,edge_index).to(device) if temporal_att else Decoder(seq_len,hidden_size_decoder,output_size,edge_index).to(device)\n",
    "\n",
    "        self.fc1 = nn.Linear(512,1)#.cuda()\n",
    "        self.tanh = nn.Tanh()#.cuda()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "    def calcPerm(self,l: list, m: int):\n",
    "        for i in permutations(l, m):\n",
    "            yield list((i))\n",
    "    \n",
    "    def forward(self, encoder_input: torch.Tensor, y_hist: torch.Tensor, sample: torch.Tensor ,return_attention: bool = False):\n",
    "        \"\"\"\n",
    "        Forward computation. encoder_input_inputs.\n",
    "\n",
    "        Args:\n",
    "            encoder_input: (torch.Tensor): tensor of input data\n",
    "            y_hist: (torch.Tensor): shifted target\n",
    "            return_attention: (bool): whether or not to return the attention\n",
    "        \"\"\"\n",
    "        attentions, encoder_output = self.encoder(encoder_input, sample)   \n",
    "\n",
    "        outputs = self.decoder(encoder_output, y_hist.float(), sample)\n",
    "        g = torch.zeros(outputs.shape[1],outputs.shape[1])#.cuda()\n",
    "        outputs = outputs.transpose(1,0)\n",
    "        idx1 = 0\n",
    "        idx2 = 0\n",
    "        for i,j in self.calcPerm(outputs, 2):\n",
    "                a = self.tanh(self.fc1(torch.cat((i,j))))\n",
    "                g[idx1,idx2] = a\n",
    "                if((idx2+1)%self.sample_size):\n",
    "                    idx2+=1\n",
    "                else:\n",
    "                    idx2 = 0\n",
    "                    idx1+= 1\n",
    "        if return_attention:\n",
    "            return outputs, attentions,g\n",
    "        return outputs,g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_index = 252\n",
    "target_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance = np.load('C:/Users/psheth5/STCD-RL/data/data/watershed.npy')\n",
    "# distance = distance[:, target_index]\n",
    "\n",
    "# spatial_matrix = []\n",
    "\n",
    "# for d in distance:\n",
    "#     if np.isfinite(d):\n",
    "#         spatial_matrix.append(1 / (d + 1))\n",
    "#     else:\n",
    "#         spatial_matrix.append(0)\n",
    "\n",
    "# spatial_matrix1 = torch.FloatTensor(spatial_matrix).cuda()\n",
    "# torch.max(spatial_matrix1)\n",
    "\n",
    "spatial_matrix1 = torch.FloatTensor(adj_mat).cuda()\n",
    "torch.max(spatial_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_size = 100\n",
    "model = AutoEncForecast(input_att=True,temporal_att=True,hidden_size_encoder=64,seq_len=30,denoising=False,directions=1,hidden_size_decoder=64,input_size=sampling_size,output_size=sampling_size,sample_size=sampling_size,edge_index=edge_index,spatial_matrix = spatial_matrix1,use_spatial=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def update_graph(sample,inferred_cg,g):\n",
    "    for i in range(len(sample)):\n",
    "        for j in range(len(sample)):\n",
    "            inferred_cg[sample[i],sample[j]] += g[i,j].cpu()\n",
    "    return inferred_cg\n",
    "\n",
    "def update_attention(sample,att,attention):\n",
    "    temp = torch.mean(att,axis=1)\n",
    "    for i in range(len(sample)):\n",
    "        for j in range(len(sample)):\n",
    "            attention[sample[i],sample[j]] += temp[i,j].cpu()\n",
    "    return attention\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def get_num_cycles(gra):\n",
    "    # gra = gra.cpu().detach().numpy()\n",
    "    G = nx.from_numpy_matrix(gra)\n",
    "    H = G.to_directed()\n",
    "    try:\n",
    "        return torch.FloatTensor([len(list(nx.find_cycle(H, orientation=\"original\")))])#.cuda()\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def is_dag(gr):\n",
    "    # gr = gr.cpu().detach().numpy()\n",
    "    G = nx.from_numpy_matrix(gr)\n",
    "    return int(nx.is_directed_acyclic_graph(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions\n",
    "def calc_discounted_rewards(rewards, gamma):\n",
    "    ''' \n",
    "    Simple implementation for better understanding\n",
    "    gets rewards of an entire episode and calculates R_t for every t\n",
    "    '''\n",
    "    \n",
    "    returns = []\n",
    "    \n",
    "    for t in range(len(rewards)):\n",
    "        ret = 0\n",
    "        \n",
    "        for t_p in range(t, len(rewards)):\n",
    "            ret += gamma ** (t_p - t) * rewards[t_p]\n",
    "            \n",
    "        returns.insert(0, ret)\n",
    "        \n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "global_step, logging_loss = 0, 0.0\n",
    "train_loss = 0.0\n",
    "reg1= True\n",
    "reg2= True\n",
    "reg_factor1= 1e-8\n",
    "reg_factor2= 1e-8\n",
    "gradient_accumulation_steps = 1\n",
    "max_grad_norm = 0.1\n",
    "logging_steps = 100\n",
    "criterion = nn.BCELoss()\n",
    "crit_mse = nn.MSELoss()\n",
    "crit_rss = nn.MSELoss(reduction='none')\n",
    "crit_nll = nn.NLLLoss()\n",
    "save_steps = 5000\n",
    "eval_during_training = False\n",
    "output_dir = \"Models\"\n",
    "lrs_step_size=5000\n",
    "do_eval=True\n",
    "reg_factor = 1\n",
    "BASELINE_REWARD = 20\n",
    "breakout = 0\n",
    "inferred_cg = np.zeros((n_features,n_features))\n",
    "attention = np.zeros((n_features,n_features))\n",
    "min_loss = 1e+5\n",
    "for epoch in tqdm(range(5), unit=\"epoch\"):\n",
    "    attentions = []\n",
    "    outputs = []\n",
    "    total_loss = 0\n",
    "    loss_1 = []\n",
    "    loss_2 = []\n",
    "    for i, batch in tqdm(enumerate(train_iter), total=len(train_iter), unit=\"batch\"):\n",
    "        original_list = list(range(3129))\n",
    "        while(len(original_list)!=0):\n",
    "            sampled_list = []\n",
    "            optimizer.zero_grad()\n",
    "            model.train()\n",
    "            feature, y_hist, target = batch\n",
    "            try:\n",
    "                sample = random.sample(original_list, sampling_size)\n",
    "            except:\n",
    "                sample = random.sample(original_list,len(original_list))\n",
    "                sample.extend(random.sample(range(feature.shape[2]),sampling_size-len(original_list)-1))\n",
    "                sample.append(0)\n",
    "            # add the sampled elements to the sampled list\n",
    "            sampled_list.extend(sample)\n",
    "            # remove the sampled elements from the original list\n",
    "            original_list = [element for element in original_list if element not in sample]\n",
    "            feature = feature[:,:,sample]\n",
    "            y_hist = y_hist[:,:,sample]\n",
    "            target = target[:,sample]\n",
    "            \n",
    "            output,att,g = model(feature.to(device), y_hist.to(device),sample,return_attention=True)\n",
    "            temp = torch.mean(att,axis=1)\n",
    "            output = output.reshape(output.shape[1],output.shape[0])\n",
    "            inferred_cg = update_graph(sample,inferred_cg,g)\n",
    "            inf_cg = torch.FloatTensor(inferred_cg)\n",
    "            attention = update_attention(sample,att,attention)\n",
    "            num_params = count_parameters(model)\n",
    "            #target = target.cuda()\n",
    "            loss2 = crit_mse(output,target)\n",
    "\n",
    "            n = torch.FloatTensor([feature.shape[0]])#.cuda()\n",
    "            cyc = torch.trace(torch.matrix_exp(inf_cg*inf_cg)) - 3129\n",
    "            bic = n*3129*(torch.log(torch.sum(crit_rss(output,target))/(3129*n))) + torch.sum(inf_cg)*torch.log(n)\n",
    "            loss = -1*(loss2 + reg_factor1*cyc + reg_factor2*bic)\n",
    "            loss_2.append(loss2)\n",
    "            loss_1.append(loss.item())\n",
    "            if(len(original_list)%1000==0):\n",
    "                print(\"The number of nodes sampled are \", 3129 - len(original_list))\n",
    "    loss_tot = 0\n",
    "    loss_21 = calc_discounted_rewards(loss_2,0.98)\n",
    "    for indexe in range(len(loss_21)):\n",
    "        loss_tot += loss_1[indexe] * torch.log(loss_21[indexe])\n",
    "    loss_tot = (loss_tot - BASELINE_REWARD) / len(loss_21)\n",
    "    loss_tot.backward()\n",
    "    optimizer.step()\n",
    "    total_loss +=loss_tot.item()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "    if(round(total_loss/(i+1),2)<=round(min_loss/(i+1),2)):\n",
    "        min_loss = total_loss\n",
    "        breakout = 0\n",
    "        torch.save(model.state_dict(),os.getcwd()+\"/Models/MyModel_GCN_FullModel_\"+str(epoch))\n",
    "    else:\n",
    "        breakout+=1\n",
    "    print(\"Loss is \", total_loss, \" for epoch \", epoch)\n",
    "    print(np.where(attention[target_index,:]!=0),len(np.where(attention[target_index,:]!=0)[0]),get_num_cycles(inferred_cg),is_dag(inferred_cg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(a_new,fname):\n",
    "    latitude = []\n",
    "    longitude = []\n",
    "    for j,i in enumerate(a_new):\n",
    "            latitude.append(float(i.split()[0]))\n",
    "            longitude.append(float(i.split()[1]))\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scattermapbox(\n",
    "        mode = \"markers\",\n",
    "        lat = longitude,\n",
    "        lon = latitude,\n",
    "        marker = { 'color':'red',\n",
    "                    'size': 10}\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(margin={'l':0,'t':0,'b':0,'r':0},\n",
    "                    mapbox={\n",
    "                        'center':{'lon':139,'lat':36.5},\n",
    "                        'style': \"stamen-terrain\",\n",
    "                        'zoom' : 4.5},\n",
    "                    width=1600,\n",
    "                    height=900,)\n",
    "    fig.show()\n",
    "    fig.write_html(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at1 = frame.columns[inferred_cg[target_index,:].argsort()[-100:]]\n",
    "plot_graph(at1,\"mapTestFT1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"attention.npy\",attention)\n",
    "np.save(\"inferred_cg.npy\",inferred_cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a6511c335c26d02572349af57853ebfcc20500c776be641a45dee87cf591594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
